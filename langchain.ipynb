{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/Yetiskin2020.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Terms & Conditions of access and use can be found at\n",
      "https://www.tandfonline.com/action/journalInformation?journalCode=hppc20\n",
      "Popular Communication\n",
      "The International Journal of Media and Culture\n",
      "ISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/hppc20\n",
      "Paratactic commoning: collective knowledge\n",
      "production networking as political struggle\n",
      "Ebru Yetiskin\n",
      "To cite this article: Ebru Yetiskin (2020): Paratactic commoning: collective knowledge production\n",
      "networking as politic\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'iText 4.2.0 by 1T3XT',\n",
       " 'creator': 'Arbortext Advanced Print Publisher 11.0.3433/W Unicode',\n",
       " 'creationdate': '2020-06-25T12:52:06+05:30',\n",
       " 'keywords': 'Commons; commoning; data; control; tactic; paratactic; obfuscation',\n",
       " 'moddate': '2020-06-30T04:01:46-07:00',\n",
       " 'source': 'docs/Yetiskin2020.pdf',\n",
       " 'total_pages': 18,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.blob_loaders import FileSystemBlobLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=vtLfCO4IGXY&ab_channel=DiEM25\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),  # fetch from youtube\n",
    "    #FileSystemBlobLoader(save_dir, glob=\"*.m4a\"),   #fetch locally\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhandbook/titles-for-programmers.md at master · basecamp/handbook · GitHub\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\nSecurity\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automa'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/titles-for-programmers.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Document Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/splitters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences\n",
    "\n",
    "| Feature                           | `RecursiveCharacterTextSplitter`              | `CharacterTextSplitter`         |\n",
    "|-----------------------------------|--------------------------------|-------------------------|\n",
    "| **Splitting Strategy**           | Tries to break at meaningful places | Splits at a fixed character (e.g., space) |\n",
    "| **Handles Word Boundaries?**      | ✅ Yes                          | ❌ No (may cut words)  |\n",
    "| **Performance**                   | Slightly slower but better structured chunks | Fast but less optimal chunks |\n",
    "| **Best for**                      | Long documents with structured text (e.g., articles, books) | Simple text that doesn’t require structure |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator=' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive splitting details\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's reduce the chunk size a bit and add a period to our separators:\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/NG2023.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token splitting\n",
    "\n",
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': 'docs/NG2023.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}, page_content='PAGE 1\\nFounder, DeepLearning.')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': 'docs/NG2023.pdf', 'total_pages': 41, 'page': 1, 'page_label': '2'}, page_content='\\nelectricity. It will \\ntransform and')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Adobe PDF Library 17.0',\n",
       " 'creator': 'Adobe InDesign 18.0 (Macintosh)',\n",
       " 'creationdate': '2022-12-13T16:08:00-05:00',\n",
       " 'moddate': '2022-12-13T16:08:04-05:00',\n",
       " 'trapped': '/False',\n",
       " 'source': 'docs/NG2023.pdf',\n",
       " 'total_pages': 41,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Adobe PDF Library 17.0',\n",
       " 'creator': 'Adobe InDesign 18.0 (Macintosh)',\n",
       " 'creationdate': '2022-12-13T16:08:00-05:00',\n",
       " 'moddate': '2022-12-13T16:08:04-05:00',\n",
       " 'trapped': '/False',\n",
       " 'source': 'docs/NG2023.pdf',\n",
       " 'total_pages': 41,\n",
       " 'page': 10,\n",
       " 'page_label': '11'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n\n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstores and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overview.png](images/overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/vectorstore.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    # Duplicate documents on purpose - messy data\n",
    "    PyPDFLoader(\"docs/Geron2017.pdf\"),\n",
    "    PyPDFLoader(\"docs/Zheng2018.pdf\"),\n",
    "    PyPDFLoader(\"docs/NG2018.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 944\n",
      "First document: page_content='Aurélien Géron\n",
      "Hands-On  \n",
      "Machine Learning  \n",
      "with Scikit-Learn  \n",
      "& TensorFlow  \n",
      "CONCEPTS, TOOLS, AND TECHNIQUES  \n",
      "TO BUILD INTELLIGENT SYSTEMS\n",
      "\u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000 \u0000w\u0000w\u0000w\u0000.\u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000.\u0000c\u0000o\u0000m' metadata={'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': '2017-03-10T21:55:34+00:00', 'author': 'Aurélien Géron', 'moddate': '2017-05-16T09:54:54+08:00', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'trapped': '/False', 'source': 'docs/Geron2017.pdf', 'total_pages': 564, 'page': 0, 'page_label': 'Cover'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total documents loaded: {len(docs)}\")\n",
    "print(f\"First document: {docs[0] if docs else 'No documents loaded'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 1605\n",
      "First Chunk: 978-1-491-96229-9\n",
      "[LSI]\n",
      "Hands-On Machine Learning with Scikit-Learn and TensorFlow\n",
      "by Aurélien Géron\n",
      "Copyright © 2017 A\n",
      "urélien Géron. All rights reserved.\n",
      "Printed in the United States of America.\n",
      "Published by O’Reilly Media, Inc., 1005 Gravenstein Highway North, Sebastopol, CA 95472.\n",
      "O’Reilly books may be purchased for educational, business, or sales promotional use. Online editions are\n",
      "also available for most titles (http://oreilly.com/safari). For more information, contact our corporate/insti‐\n",
      "tutional sales department: 800-998-9938 or corporate@oreilly.com.\n",
      "Editor: Nicole Tache\n",
      "Production Editor: N\n",
      "icholas Adams\n",
      "Copyeditor: Rachel Monaghan\n",
      "Proofreader: Charles Roumeliotis\n",
      "Indexer: Wendy Catalano\n",
      "Interior Designer: Da\n",
      "vid Futato\n",
      "Cover Designer: Randy Comer\n",
      "Illustrator: Rebecca Demarest\n",
      "March 2017:  First Edition\n",
      "Revision History for the First Edition\n",
      "2017-03-10: First Release\n",
      "See h\n",
      "ttp://oreilly.com/catalog/errata.csp?isbn=9781491962299 for release details.\n",
      "The O’Reilly logo is a registered trademark of O’Reilly Media, Inc. Hands-On Machine Learning with\n",
      "Scikit-Learn and TensorFlow, the cover image, and related trade dress are trademarks of O’Reilly Media,\n",
      "Inc.\n",
      "While the publisher and the author have used good faith efforts to ensure that the information and\n",
      "instructions contained in this work are accurate, the publisher and the author disclaim all responsibility\n",
      "for errors or omissions, including without limitation responsibility for damages resulting from the use of\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Chunks: {len(splits)}\")\n",
    "print(f\"First Chunk: {splits[3].page_content}\")  # Show first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first element in splits: <class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of first element in splits: {type(splits[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_68203/1333021179.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631510802407727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702031204123162"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759053971445477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure `splits` is converted into a list of Document objects\n",
    "documents = [doc for doc in splits if doc.page_content.strip()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid documents: 1605\n",
      "First document content: Aurélien Géron\n",
      "Hands-On  \n",
      "Machine Learning  \n",
      "with Scikit-Learn  \n",
      "& TensorFlow  \n",
      "CONCEPTS, TOOLS, AND TECHNIQUES  \n",
      "TO BUILD INTELLIGENT SYSTEMS\n",
      "\u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000 \u0000w\u0000w\u0000w\u0000\n",
      "First document metadata: {'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': '2017-03-10T21:55:34+00:00', 'author': 'Aurélien Géron', 'moddate': '2017-05-16T09:54:54+08:00', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'trapped': '/False', 'source': 'docs/Geron2017.pdf', 'total_pages': 564, 'page': 0, 'page_label': 'Cover'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total valid documents: {len(documents)}\")\n",
    "print(f\"First document content: {documents[0].page_content[:200]}\")  # Print first 200 characters\n",
    "print(f\"First document metadata: {documents[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Surrogate Unicode Characters\n",
    "import unicodedata\n",
    "from langchain.schema import Document\n",
    "\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize(\"NFKD\", text).encode(\"utf-8\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=clean_text(doc.page_content), metadata=doc.metadata)\n",
    "    for doc in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# try persist_directory=None if you get tenant error. It can also work in-memory mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815\n",
      "[Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 1, 'page_label': '2', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Machine Learning Yearning is a\\n \\n \\ndeeplearning.ai project.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© 2018 Andrew Ng. All Rights Reserved.\\n \\n \\n \\n \\nPage 2\\nMachine Learning Yearning-Draft\\nAndrew Ng'), Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 1, 'page_label': '2', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Machine Learning Yearning is a\\n \\n \\ndeeplearning.ai project.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© 2018 Andrew Ng. All Rights Reserved.\\n \\n \\n \\n \\nPage 2\\nMachine Learning Yearning-Draft\\nAndrew Ng'), Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 1, 'page_label': '2', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Machine Learning Yearning is a\\n \\n \\ndeeplearning.ai project.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© 2018 Andrew Ng. All Rights Reserved.\\n \\n \\n \\n \\nPage 2\\nMachine Learning Yearning-Draft\\nAndrew Ng')]\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())  # Number of stored embeddings\n",
    "print(vectordb.similarity_search(\"What is AI?\", k=3))  # Test retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 91, 'page_label': '92', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'), Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 91, 'page_label': '92', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'), Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 91, 'page_label': '92', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng')]\n"
     ]
    }
   ],
   "source": [
    "docs_ss= vectordb.similarity_search(\"What are neural networks?\", k=3)\n",
    "print(docs_ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 **Result 1:**\n",
      "📄 Source: docs/NG2018.pdf, Page: 91\n",
      "📝 Content:\n",
      "Neural networks are commonly used in end-to-end learning systems. The term “end-\n",
      "to-end”   refers to the fact that we are asking the learning algorithm to go\n",
      "directly from the input to   the desired output. I.e., the learning algorithm\n",
      "directly connects the “input end” of the   system to the “output end.”   In\n",
      "problems where data is abundant, end-to-end systems have been remarkably\n",
      "successful.   But they are not always a good choice. The next few chapters will\n",
      "give more examples of   end-to-end systems as well as give advice on when you\n",
      "should and should not use them.                       Page 92 Machine Learning\n",
      "Yearning-Draft Andrew Ng\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 **Result 2:**\n",
      "📄 Source: docs/Geron2017.pdf, Page: 277\n",
      "📝 Content:\n",
      "4 In the context of Machine Learning, the phrase “neural networks” generally\n",
      "refers to ANNs, not BNNs. 5 Drawing of a cortical lamination by S. Ramon y Cajal\n",
      "(public domain). Reproduced from https://en.w ikipe\n",
      "dia.org/wiki/Cerebral_cortex. works (BNN)4 is still the subject of active\n",
      "research, but some parts of the brain ha ve been mapped, and it seems tha t\n",
      "neurons are often organized in consecutive layers, as  shown in Figure 10-2.\n",
      "Figure 10-2. Multiple layers in a biological neural network (human cortex)5\n",
      "Logical Computations with Neurons Warren McCulloch and W alter Pitts proposed a\n",
      "very simple model of the biological neuron, which later became known as an\n",
      "artificial neuron: it has one or more binar y (on/off) in puts and one binary\n",
      "output. The artificial neuron simply activates its out‐ put when more than a\n",
      "certain number of its inputs are active. McCulloch and Pitts showed that even\n",
      "with such a simplified model it is possible to build a network of artificial\n",
      "neurons that computes any logical proposition you want. For example, let’s build\n",
      "a few ANNs that perform various logical computations (see Figure 10-3), assuming\n",
      "that a neuron is activated when at least two of its inputs are active. Figure\n",
      "10-3. ANNs performing simple logical computations 256 | Chapter 10: Introduction\n",
      "to Artificial Neural Networks \u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000\n",
      "\u0000w\u0000w\u0000w\u0000.\u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000.\u0000c\u0000o\u0000m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 **Result 3:**\n",
      "📄 Source: docs/Geron2017.pdf, Page: 374\n",
      "📝 Content:\n",
      "CHAPTER 13 Convolutional Neural Networks Although IBM’s Deep Blue supercom puter\n",
      "beat the chess world champion Garry Kas‐ parov back in 1996, until quite\n",
      "recently computers were unable to reliably perform seemingly trivial tasks such\n",
      "as detecting a puppy in a picture or recognizing spoken words. Why are these\n",
      "tasks so effortless to us humans? The answer lies in the fact that perception\n",
      "largely takes place outside the realm of our consciousness, within special‐ ized\n",
      "visual, auditory, and other sensory modules in our brains. By the time sensory\n",
      "information reaches our consciousness, it is already adorned with high-level\n",
      "features; for example, when you look at a picture of a cute puppy, you cannot\n",
      "choose not to see the puppy, or not to notice its cuteness. Nor can you explain\n",
      "how you recognize a cute puppy; it’s just obvious to you. Thus, we cannot trust\n",
      "our subjective experience: per‐ ception is not trivial at all, and to understand\n",
      "it we must look at how the sensory modules work. Convolutional neural networks\n",
      "(CNNs) emerged from the study of the brain’s visual cortex, and they have been\n",
      "used in image recognition since the 1980s. In the last few years, thanks to the\n",
      "increase in computational power, the amount of available training data, and the\n",
      "tricks presented in Chapter 11 for training deep nets, CNNs have man‐ aged to\n",
      "achieve superhuman performance on some complex visual tasks. They power image\n",
      "search services, self-driving cars, automatic video classification systems, and\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "# Print formatted results\n",
    "for i, doc in enumerate(docs_ss):\n",
    "    print(f\"\\n🔹 **Result {i+1}:**\")\n",
    "    print(f\"📄 Source: {doc.metadata.get('source', 'Unknown')}, Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "    print(\"📝 Content:\")\n",
    "    print(textwrap.fill(doc.page_content, width=80))  # Wrap text to 80 characters\n",
    "    print(\"-\" * 100)  # Divider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "Let's get our vectorDB from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/MMR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/LLM_retrieval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/compression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(metadata={}, page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(\"What are neural networks?\", k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Specificity: working with metadata\n",
    "\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about regression in the second lecture?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/NG2018.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creationdate': '', 'creator': 'PyPDF', 'page': 54, 'page_label': '55', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}\n",
      "{'creationdate': '', 'creator': 'PyPDF', 'page': 47, 'page_label': '48', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}\n",
      "{'creationdate': '', 'creator': 'PyPDF', 'page': 8, 'page_label': '9', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/NG2018.pdf`, `docs/Zheng2018.pdf`, or `docs/Geron2017.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_68203/1248247315.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "document_content_description = \"AI books\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    structured_query_translator=ChromaTranslator(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about artifical intelligence in the second book?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\n```json\n{\n    \"query\": \"artificial intelligence\",\n    \"filter\": \"eq(\\\"source\\\", \\\"docs/Zheng2018.pdf\\\") and eq(\\\"page\\\", 2)\"\n}\n```\n raised following error:\nUnexpected token Token('CNAME', 'and') at line 1, column 36.\nExpected one of: \n\t* $END\nPrevious tokens: [Token('RPAR', ')')]\n\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/lexer.py:665\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    664\u001b[0m         lexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlexers[parser_state\u001b[38;5;241m.\u001b[39mposition]\n\u001b[0;32m--> 665\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mlexer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/lexer.py:598\u001b[0m, in \u001b[0;36mBasicLexer.next_token\u001b[0;34m(self, lex_state, parser_state)\u001b[0m\n\u001b[1;32m    597\u001b[0m         allowed \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<END-OF-FILE>\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[0;32m--> 598\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedCharacters(lex_state\u001b[38;5;241m.\u001b[39mtext, line_ctr\u001b[38;5;241m.\u001b[39mchar_pos, line_ctr\u001b[38;5;241m.\u001b[39mline, line_ctr\u001b[38;5;241m.\u001b[39mcolumn,\n\u001b[1;32m    599\u001b[0m                                allowed\u001b[38;5;241m=\u001b[39mallowed, token_history\u001b[38;5;241m=\u001b[39mlex_state\u001b[38;5;241m.\u001b[39mlast_token \u001b[38;5;129;01mand\u001b[39;00m [lex_state\u001b[38;5;241m.\u001b[39mlast_token],\n\u001b[1;32m    600\u001b[0m                                state\u001b[38;5;241m=\u001b[39mparser_state, terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[1;32m    602\u001b[0m value, type_ \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[0;31mUnexpectedCharacters\u001b[0m: No terminal matches 'a' in the current parser context, at line 1 col 36\n\neq(\"source\", \"docs/Zheng2018.pdf\") and eq(\"page\", 2)\n                                   ^\nExpected one of: \n\t* RSQB\n\t* COMMA\n\t* RPAR\n\nPrevious tokens: Token('RPAR', ')')\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:58\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mast_parse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfilter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/lark.py:655\u001b[0m, in \u001b[0;36mLark.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Parse the given text, according to the options provided.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \n\u001b[1;32m    640\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 655\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/parser_frontends.py:104\u001b[0m, in \u001b[0;36mParsingFrontend.parse\u001b[0;34m(self, text, start, on_error)\u001b[0m\n\u001b[1;32m    103\u001b[0m stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_lexer_thread(text)\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchosen_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:42\u001b[0m, in \u001b[0;36mLALR_Parser.parse\u001b[0;34m(self, lexer, start, on_error)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedInput \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:88\u001b[0m, in \u001b[0;36m_Parser.parse\u001b[0;34m(self, lexer, start, value_stack, state_stack, start_interactive)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m InteractiveParser(\u001b[38;5;28mself\u001b[39m, parser_state, parser_state\u001b[38;5;241m.\u001b[39mlexer)\n\u001b[0;32m---> 88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_from_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparser_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:111\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/parsers/lalr_parser.py:100\u001b[0m, in \u001b[0;36m_Parser.parse_from_state\u001b[0;34m(self, state, last_token)\u001b[0m\n\u001b[1;32m     99\u001b[0m token \u001b[38;5;241m=\u001b[39m last_token\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m state\u001b[38;5;241m.\u001b[39mlexer\u001b[38;5;241m.\u001b[39mlex(state):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/lark/lexer.py:674\u001b[0m, in \u001b[0;36mContextualLexer.lex\u001b[0;34m(self, lexer_state, parser_state)\u001b[0m\n\u001b[1;32m    673\u001b[0m     token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_lexer\u001b[38;5;241m.\u001b[39mnext_token(lexer_state, parser_state)\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedToken(token, e\u001b[38;5;241m.\u001b[39mallowed, state\u001b[38;5;241m=\u001b[39mparser_state, token_history\u001b[38;5;241m=\u001b[39m[last_token], terminals_by_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_lexer\u001b[38;5;241m.\u001b[39mterminals_by_name)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m UnexpectedCharacters:\n",
      "\u001b[0;31mUnexpectedToken\u001b[0m: Unexpected token Token('CNAME', 'and') at line 1, column 36.\nExpected one of: \n\t* $END\nPrevious tokens: [Token('RPAR', ')')]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:181\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     emit_warning()\n\u001b[0;32m--> 181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/retrievers.py:410\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_name:\n\u001b[1;32m    409\u001b[0m     config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_name\n\u001b[0;32m--> 410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/retrievers.py:259\u001b[0m, in \u001b[0;36mBaseRetriever.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 259\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain/retrievers/self_query/base.py:301\u001b[0m, in \u001b[0;36mSelfQueryRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_relevant_documents\u001b[39m(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m, query: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m, run_manager: CallbackManagerForRetrieverRun\n\u001b[1;32m    292\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Document]:\n\u001b[1;32m    293\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get documents relevant for a query.\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \n\u001b[1;32m    295\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;124;03m        List of relevant documents\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m     structured_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_constructor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    305\u001b[0m         logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGenerated Query: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructured_query\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/runnables/base.py:5360\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5355\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5356\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5357\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5358\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5359\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5361\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5362\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5363\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5364\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/runnables/base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:202\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[1;32m    195\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_with_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minner_input\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/runnables/base.py:1922\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[0;34m(self, func, input, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[1;32m   1918\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m   1919\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[1;32m   1920\u001b[0m     output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m   1921\u001b[0m         Output,\n\u001b[0;32m-> 1922\u001b[0m         \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1923\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcall_func_with_variable_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1924\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1925\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1926\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1928\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1930\u001b[0m     )\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1932\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/runnables/config.py:396\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[0;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[1;32m    395\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[0;32m--> 396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:203\u001b[0m, in \u001b[0;36mBaseOutputParser.invoke.<locals>.<lambda>\u001b[0;34m(inner_input)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_result(\n\u001b[1;32m    195\u001b[0m             [ChatGeneration(message\u001b[38;5;241m=\u001b[39minner_input)]\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m--> 203\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m inner_input: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mGeneration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minner_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    204\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m    205\u001b[0m         config,\n\u001b[1;32m    206\u001b[0m         run_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    207\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain_core/output_parsers/base.py:247\u001b[0m, in \u001b[0;36mBaseOutputParser.parse_result\u001b[0;34m(self, result, partial)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, result: \u001b[38;5;28mlist\u001b[39m[Generation], \u001b[38;5;241m*\u001b[39m, partial: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    233\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse a list of candidate model Generations into a specific format.\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \n\u001b[1;32m    235\u001b[0m \u001b[38;5;124;03m    The return value is parsed from only the first Generation in the result, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;124;03m        Structured output.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/LLM/lib/python3.10/site-packages/langchain/chains/query_constructor/base.py:65\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredQuery(\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m allowed_keys}\n\u001b[1;32m     63\u001b[0m     )\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     66\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing text\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m raised following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     67\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Parsing text\n```json\n{\n    \"query\": \"artificial intelligence\",\n    \"filter\": \"eq(\\\"source\\\", \\\"docs/Zheng2018.pdf\\\") and eq(\\\"page\\\", 2)\"\n}\n```\n raised following error:\nUnexpected token Token('CNAME', 'and') at line 1, column 36.\nExpected one of: \n\t* $END\nPrevious tokens: [Token('RPAR', ')')]\n\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE "
     ]
    }
   ],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "• There is now a huge quantity of data available to train neural networks, and\n",
      "ANNs frequen tly outperform other ML techniques on ver\n",
      "y large and complex\n",
      "problems.\n",
      "• The tremendous increase in computing power since the 1990s now makes it pos‐\n",
      "sible to train large neural networks in a reasonable amount of time. This is in\n",
      "part due to Moore\n",
      "’s Law, but also thanks to the gaming industry, which has pro‐\n",
      "duced powerful GPU cards by the millions.\n",
      "• The training algorithms have been improved. To be fair they are only slightly dif‐\n",
      "ferent from the ones used in the 1990s, but these relatively small tweaks ha\n",
      "ve a\n",
      "huge positive impact.\n",
      "• Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
      "For example, man\n",
      "y people thought that ANN training algorithms were doomed\n",
      "because they were likely to get stuck in local optima, but it turns out that this is\n",
      "rather rare in practice (or when it is the case, they are usually fairly close to the\n",
      "global optimum).\n",
      "• ANNs seem to have entered a virtuous circle of funding and progress. Amazing\n",
      "products based on ANNs regularly make the headline news, which pulls more\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "• There is now a huge quantity of data available to train neural networks, and\n",
      "ANNs frequen tly outperform other ML techniques on ver\n",
      "y large and complex\n",
      "problems.\n",
      "• The tremendous increase in computing power since the 1990s now makes it pos‐\n",
      "sible to train large neural networks in a reasonable amount of time. This is in\n",
      "part due to Moore\n",
      "’s Law, but also thanks to the gaming industry, which has pro‐\n",
      "duced powerful GPU cards by the millions.\n",
      "• The training algorithms have been improved. To be fair they are only slightly dif‐\n",
      "ferent from the ones used in the 1990s, but these relatively small tweaks ha\n",
      "ve a\n",
      "huge positive impact.\n",
      "• Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
      "For example, man\n",
      "y people thought that ANN training algorithms were doomed\n",
      "because they were likely to get stuck in local optima, but it turns out that this is\n",
      "rather rare in practice (or when it is the case, they are usually fairly close to the\n",
      "global optimum).\n",
      "• ANNs seem to have entered a virtuous circle of funding and progress. Amazing\n",
      "products based on ANNs regularly make the headline news, which pulls more\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "• There is now a huge quantity of data available to train neural networks, and\n",
      "ANNs frequen tly outperform other ML techniques on ver\n",
      "y large and complex\n",
      "problems.\n",
      "• The tremendous increase in computing power since the 1990s now makes it pos‐\n",
      "sible to train large neural networks in a reasonable amount of time. This is in\n",
      "part due to Moore\n",
      "’s Law, but also thanks to the gaming industry, which has pro‐\n",
      "duced powerful GPU cards by the millions.\n",
      "• The training algorithms have been improved. To be fair they are only slightly dif‐\n",
      "ferent from the ones used in the 1990s, but these relatively small tweaks ha\n",
      "ve a\n",
      "huge positive impact.\n",
      "• Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
      "For example, man\n",
      "y people thought that ANN training algorithms were doomed\n",
      "because they were likely to get stuck in local optima, but it turns out that this is\n",
      "rather rare in practice (or when it is the case, they are usually fairly close to the\n",
      "global optimum).\n",
      "• ANNs seem to have entered a virtuous circle of funding and progress. Amazing\n",
      "products based on ANNs regularly make the headline news, which pulls more\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "- \"Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions.\"\n",
      "- \"It seems only logical, then, to look at the brain’s architecture for inspiration on how to build an intelligent machine.\"\n",
      "- \"This is the key idea that inspired artificial neural networks (ANNs).\"\n",
      "- \"ANNs are at the very core of Deep Learning.\"\n",
      "- \"They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex Machine Learning tasks.\"\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about ai?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of Retrival\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/NG2023.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='✓\\n✓\\nOvercoming Imposter Syndrome PAGE 40\\nMake Every Day Count\\nFinal Thoughts\\nEvery year on my birthday, I get to thinking about the days behind and those \\nthat may lie ahead.\\nWhen I ask friends, many choose a number in the hundreds of \\nthousands. (Many others can’t resist calculating the answer, \\nto my annoyance!)\\nWhen I was a grad student, I remember plugging my statistics \\ninto a mortality calculator to figure out my life expectancy. \\nThe calculator said I could expect to live a total of 27,649 \\ndays. It struck me how small this number is. I printed it in a \\nlarge font and pasted it on my office wall as a daily reminder.\\nThat’s all the days we have to spend with loved ones, learn, \\nbuild for the future, and help others. Whatever you’re doing \\ntoday, is it worth 1/30,000 of your life?\\nHow many days is a \\ntypical human lifespan?\\nMaybe you’re good at math; I’m sure you’ll be able to answer the following question \\nvia a quick calculation. But let me ask you a question, and please answer from \\nyour gut, without calculating.\\n20,000 days 100,000 days\\n1 million days 5 million days PAGE 41')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this book?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='algorithms, deployment processes, and software stacks a particular company uses. You \\nmay be surprised — if you’re not already familiar with the data-centric AI movement — to \\nlearn how much time most machine learning engineers spend iteratively cleaning datasets.\\n✓\\n✓\\nWhat do you do in a typical week or day?\\nWhat are the most important tasks in this role?\\nWhat skills are most important for success?\\nHow does your team work together to accomplish its goals?\\nWhat is the hiring process?\\nConsidering candidates who stood out in the past, what enabled them to shine?\\n✓\\n✓\\n✓\\n✓\\n✓\\n✓\\nUsing Informational Interviews to Find the Right Job CHAPTER 8 PAGE 30\\nFinding someone to interview isn’t always easy, but many people who are in senior positions today \\nreceived help when they were new from those who had entered the field ahead of them, and many \\nare eager to pay it forward. If you can reach out to someone who’s already in your network — \\nperhaps a friend who made the transition ahead of you or someone who attended the same school \\nas you — that’s great! Meetups such as Pie & AI can also help you build your network.\\nFinally, be polite and professional, and thank the people you’ve interviewed. And when you get \\na chance, please pay it forward as well and help someone coming up after you. If you receive \\na request for an informational interview from someone in the DeepLearning.AI community, \\nI hope you’ll lean in to help them take a step up! If you’re interested in learning more about')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about ethics\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_68203/3010969844.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this book?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_68203/4094420968.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The major topics covered in this book \"Feature Engineering for Machine Learning: Principles and Techniques for Data Scientists\" include:\\n- What is Machine Learning and the problems it solves\\n- Main categories and fundamental concepts of Machine Learning systems\\n- Steps in a typical Machine Learning project\\n- Learning by fitting a model to data\\n- Optimizing a cost function\\n- Handling, cleaning, and preparing data\\n- Selecting and engineering features\\n- Selecting a model and tuning hyperparameters using cross-validation\\n- Main challenges of Machine Learning, such as underfitting and overfitting (bias/variance tradeoff)'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
