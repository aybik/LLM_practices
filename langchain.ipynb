{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/Yetiskin2020.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Terms & Conditions of access and use can be found at\n",
      "https://www.tandfonline.com/action/journalInformation?journalCode=hppc20\n",
      "Popular Communication\n",
      "The International Journal of Media and Culture\n",
      "ISSN: (Print) (Online) Journal homepage: https://www.tandfonline.com/loi/hppc20\n",
      "Paratactic commoning: collective knowledge\n",
      "production networking as political struggle\n",
      "Ebru Yetiskin\n",
      "To cite this article: Ebru Yetiskin (2020): Paratactic commoning: collective knowledge production\n",
      "networking as politic\n"
     ]
    }
   ],
   "source": [
    "print(page.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'iText 4.2.0 by 1T3XT',\n",
       " 'creator': 'Arbortext Advanced Print Publisher 11.0.3433/W Unicode',\n",
       " 'creationdate': '2020-06-25T12:52:06+05:30',\n",
       " 'keywords': 'Commons; commoning; data; control; tactic; paratactic; obfuscation',\n",
       " 'moddate': '2020-06-30T04:01:46-07:00',\n",
       " 'source': 'docs/Yetiskin2020.pdf',\n",
       " 'total_pages': 18,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Youtube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.blob_loaders import FileSystemBlobLoader\n",
    "from langchain.document_loaders.parsers import OpenAIWhisperParser\n",
    "from langchain.document_loaders.blob_loaders.youtube_audio import YoutubeAudioLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.youtube.com/watch?v=vtLfCO4IGXY&ab_channel=DiEM25\"\n",
    "save_dir=\"docs/youtube/\"\n",
    "loader = GenericLoader(\n",
    "    YoutubeAudioLoader([url],save_dir),  # fetch from youtube\n",
    "    #FileSystemBlobLoader(save_dir, glob=\"*.m4a\"),   #fetch locally\n",
    "    OpenAIWhisperParser()\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nhandbook/titles-for-programmers.md at master · basecamp/handbook · GitHub\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSkip to content\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNavigation Menu\\n\\nToggle navigation\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Sign in\\n          \\n\\n\\n\\n\\n\\n\\n\\n\\n        Product\\n        \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nGitHub Copilot\\n        Write better code with AI\\n      \\n\\n\\n\\n\\n\\n\\n\\nSecurity\\n        Find and fix vulnerabilities\\n      \\n\\n\\n\\n\\n\\n\\n\\nActions\\n        Automa'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://github.com/basecamp/handbook/blob/master/titles-for-programmers.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Document Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alt text](images/splitters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Differences\n",
    "\n",
    "| Feature                           | `RecursiveCharacterTextSplitter`              | `CharacterTextSplitter`         |\n",
    "|-----------------------------------|--------------------------------|-------------------------|\n",
    "| **Splitting Strategy**           | Tries to break at meaningful places | Splits at a fixed character (e.g., space) |\n",
    "| **Handles Word Boundaries?**      | ✅ Yes                          | ❌ No (may cut words)  |\n",
    "| **Performance**                   | Slightly slower but better structured chunks | Fast but less optimal chunks |\n",
    "| **Best for**                      | Long documents with structured text (e.g., articles, books) | Simple text that doesn’t require structure |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size =26\n",
    "chunk_overlap = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap\n",
    ")\n",
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    separator=' '\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = 'abcdefghijklmnopqrstuvwxyz'\n",
    "r_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abcdefghijklmnopqrstuvwxyz', 'wxyzabcdefg']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'abcdefghijklmnopqrstuvwxyzabcdefg'\n",
    "r_splitter.split_text(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = \"a b c d e f g h i j k l m n o p q r s t u v w x y z\"\n",
    "r_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a b c d e f g h i j k l m', 'l m n o p q r s t u v w x', 'w x y z']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive splitting details\n",
    "\n",
    "`RecursiveCharacterTextSplitter` is recommended for generic text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_text = \"\"\"When writing documents, writers will use document structure to group content. \\\n",
    "This can convey to the reader, which idea's are related. For example, closely related ideas \\\n",
    "are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n  \\\n",
    "Paragraphs are often delimited with a carriage return or two carriage returns. \\\n",
    "Carriage returns are the \"backslash n\" you see embedded in this string. \\\n",
    "Sentences have a period at the end, but also, have a space.\\\n",
    "and words are separated by space.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "496"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_splitter = CharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separator = ' '\n",
    ")\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=450,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['When writing documents, writers will use document structure to group content. This can convey to the reader, which idea\\'s are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document. \\n\\n Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also,',\n",
       " 'have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example, closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.\",\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"When writing documents, writers will use document structure to group content. This can convey to the reader, which idea's are related. For example,\",\n",
       " 'closely related ideas are in sentances. Similar ideas are in paragraphs. Paragraphs form a document.',\n",
       " 'Paragraphs are often delimited with a carriage return or two carriage returns. Carriage returns are the \"backslash n\" you see embedded in this',\n",
       " 'string. Sentences have a period at the end, but also, have a space.and words are separated by space.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's reduce the chunk size a bit and add a period to our separators:\n",
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"\\. \", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "r_splitter.split_text(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"docs/NG2023.pdf\")\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = text_splitter.split_documents(pages)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token splitting\n",
    "\n",
    "We can also split on token count explicity, if we want.\n",
    "\n",
    "This can be useful because LLMs often have context windows designated in tokens.\n",
    "\n",
    "Tokens are often ~4 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=1, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['foo', ' bar', ' b', 'az', 'zy', 'foo']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"foo bar bazzyfoo\"\n",
    "text_splitter.split_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(chunk_size=10, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': 'docs/NG2023.pdf', 'total_pages': 41, 'page': 0, 'page_label': '1'}, page_content='PAGE 1\\nFounder, DeepLearning.')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0', 'creator': 'Adobe InDesign 18.0 (Macintosh)', 'creationdate': '2022-12-13T16:08:00-05:00', 'moddate': '2022-12-13T16:08:04-05:00', 'trapped': '/False', 'source': 'docs/NG2023.pdf', 'total_pages': 41, 'page': 1, 'page_label': '2'}, page_content='\\nelectricity. It will \\ntransform and')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Adobe PDF Library 17.0',\n",
       " 'creator': 'Adobe InDesign 18.0 (Macintosh)',\n",
       " 'creationdate': '2022-12-13T16:08:00-05:00',\n",
       " 'moddate': '2022-12-13T16:08:04-05:00',\n",
       " 'trapped': '/False',\n",
       " 'source': 'docs/NG2023.pdf',\n",
       " 'total_pages': 41,\n",
       " 'page': 0,\n",
       " 'page_label': '1'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Adobe PDF Library 17.0',\n",
       " 'creator': 'Adobe InDesign 18.0 (Macintosh)',\n",
       " 'creationdate': '2022-12-13T16:08:00-05:00',\n",
       " 'moddate': '2022-12-13T16:08:04-05:00',\n",
       " 'trapped': '/False',\n",
       " 'source': 'docs/NG2023.pdf',\n",
       " 'total_pages': 41,\n",
       " 'page': 10,\n",
       " 'page_label': '11'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[10].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context aware splitting\n",
    "\n",
    "Chunking aims to keep text with common context together.\n",
    "\n",
    "A text splitting often uses sentences or other delimiters to keep related text together but many documents (such as Markdown) have structure (headers) that can be explicitly used in splitting.\n",
    "\n",
    "We can use `MarkdownHeaderTextSplitter` to preserve header metadata in our chunks, as show below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import MarkdownHeaderTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_document = \"\"\"# Title\\n\\n \\\n",
    "## Chapter 1\\n\\n \\\n",
    "Hi this is Jim\\n\\n Hi this is Joe\\n\\n \\\n",
    "### Section \\n\\n \\\n",
    "Hi this is Lance \\n\\n\n",
    "## Chapter 2\\n\\n \\\n",
    "Hi this is Molly\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(\n",
    "    headers_to_split_on=headers_to_split_on\n",
    ")\n",
    "md_header_splits = markdown_splitter.split_text(markdown_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1'}, page_content='Hi this is Jim  \\nHi this is Joe')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'Header 1': 'Title', 'Header 2': 'Chapter 1', 'Header 3': 'Section'}, page_content='Hi this is Lance')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorstores and Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![overview.png](images/overview.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/vectorstore.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Load PDF\n",
    "loaders = [\n",
    "    PyPDFLoader(\"docs/Geron2017.pdf\"),\n",
    "    PyPDFLoader(\"docs/NG2018.pdf\")\n",
    "]\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents loaded: 682\n",
      "First document: page_content='Aurélien Géron\n",
      "Hands-On  \n",
      "Machine Learning  \n",
      "with Scikit-Learn  \n",
      "& TensorFlow  \n",
      "CONCEPTS, TOOLS, AND TECHNIQUES  \n",
      "TO BUILD INTELLIGENT SYSTEMS\n",
      "\u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000 \u0000w\u0000w\u0000w\u0000.\u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000.\u0000c\u0000o\u0000m' metadata={'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': '2017-03-10T21:55:34+00:00', 'author': 'Aurélien Géron', 'moddate': '2017-05-16T09:54:54+08:00', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'trapped': '/False', 'source': 'docs/Geron2017.pdf', 'total_pages': 564, 'page': 0, 'page_label': 'Cover'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total documents loaded: {len(docs)}\")\n",
    "print(f\"First document: {docs[0] if docs else 'No documents loaded'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks: 1211\n",
      "First Chunk: Aurélien Géron\n",
      "Hands-On  \n",
      "Machine Learning  \n",
      "with Scikit-Learn  \n",
      "& TensorFlow  \n",
      "CONCEPTS, TOOLS, AND TECHNIQUES  \n",
      "TO BUILD INTELLIGENT SYSTEMS\n",
      "\u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000 \u0000w\u0000w\u0000w\u0000.\u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000.\u0000c\u0000o\u0000m\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Chunks: {len(splits)}\")\n",
    "print(f\"First Chunk: {splits[0].page_content}\")  # Show first chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of first element in splits: <class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Type of first element in splits: {type(splits[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_17578/1333021179.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "embedding = OpenAIEmbeddings(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.027551146146196668,\n",
       " -0.005382069836976813,\n",
       " -0.02582130760099973,\n",
       " -0.03305632611697975,\n",
       " -0.027349121791237472,\n",
       " 0.022639416094150544,\n",
       " -0.010435849398653005,\n",
       " -0.008125188737472597,\n",
       " 0.0025079497065223677,\n",
       " -0.019646922070829638,\n",
       " 0.000673547850878873,\n",
       " 0.02924310407710086,\n",
       " -0.00539785296060417,\n",
       " 0.0007114275338490437,\n",
       " 0.0002138622943082356,\n",
       " 0.0140786105368597,\n",
       " 0.029874432747485417,\n",
       " -0.001194787906827953,\n",
       " 0.004210956382759252,\n",
       " -0.0038700394688583597,\n",
       " -0.011692191441061522,\n",
       " 0.006875160130779538,\n",
       " 0.012992726602155665,\n",
       " -0.04724857570274996,\n",
       " -0.0022980333240882078,\n",
       " 0.004706548979229199,\n",
       " 0.016932211768408267,\n",
       " -0.00013178968182733469,\n",
       " -0.02588444009550916,\n",
       " -0.016351390583747363,\n",
       " 0.02669254124063623,\n",
       " 0.0029972288672768573,\n",
       " -0.01551803755840361,\n",
       " -0.024760676477834954,\n",
       " 0.006035494135381614,\n",
       " -0.014949843245173624,\n",
       " 0.009785581352444648,\n",
       " -0.011515419897641582,\n",
       " -0.004349848708870307,\n",
       " -0.01087777872286414,\n",
       " -0.017058478620072263,\n",
       " 0.011180816186625503,\n",
       " 0.006938292625288966,\n",
       " -0.02204596803805873,\n",
       " -0.0025758175106490306,\n",
       " 0.010044425697520384,\n",
       " 0.004545560559436617,\n",
       " -0.021364133744595656,\n",
       " -0.021919703049039875,\n",
       " -0.005659854023537636,\n",
       " 0.004779151627311812,\n",
       " -0.009558303254623623,\n",
       " -0.01757616731022374,\n",
       " -0.014823577324832197,\n",
       " -0.007998923748453743,\n",
       " 0.0153033863320135,\n",
       " -0.002143357874349797,\n",
       " 0.0026910349184884066,\n",
       " -0.0005374178275163135,\n",
       " -0.015858955636457717,\n",
       " 0.007317089454990672,\n",
       " 0.005697733706507806,\n",
       " -0.021212615012714976,\n",
       " 0.019545908962027465,\n",
       " -0.005707203394419706,\n",
       " -0.006616315785703801,\n",
       " 0.03045525393214632,\n",
       " 0.02518998079326032,\n",
       " 0.003144012522370947,\n",
       " 0.010783079049777426,\n",
       " 0.014735191087460941,\n",
       " -0.009267892662293173,\n",
       " -0.018914582154288054,\n",
       " 0.02294245355791191,\n",
       " 0.015505411618295268,\n",
       " 0.013497789352198798,\n",
       " 0.0011829505641074353,\n",
       " -0.0053631299954917284,\n",
       " 0.004482427599265904,\n",
       " -0.0070014255854596785,\n",
       " 0.022109100532568156,\n",
       " -0.039849411583458345,\n",
       " -0.0018213808019339895,\n",
       " -0.0058745052499277455,\n",
       " 0.009242638919431344,\n",
       " 0.004157293576161725,\n",
       " -0.019571162704889296,\n",
       " 0.005470455608686783,\n",
       " 0.0017771877996636833,\n",
       " -0.007992610312738286,\n",
       " 0.010656814060758572,\n",
       " 0.029192598454022348,\n",
       " 0.004886477240506866,\n",
       " 0.03388967727967836,\n",
       " -0.019255498369697015,\n",
       " 0.0029451444196081943,\n",
       " -0.0068688466950640814,\n",
       " 0.01501297573968305,\n",
       " -0.004043654527251213,\n",
       " -0.022778307954600313,\n",
       " 0.0009706665268646578,\n",
       " 0.004981176447932293,\n",
       " -0.013308390937347944,\n",
       " -0.0015846328997857447,\n",
       " -0.00761381348303658,\n",
       " -0.0050569358138726345,\n",
       " 0.0008925397389463416,\n",
       " -0.01590946125953623,\n",
       " 0.017071103628858032,\n",
       " 0.00040720644641018233,\n",
       " 0.00037149697786336973,\n",
       " 0.03287955364223724,\n",
       " 0.017929710397063616,\n",
       " -0.048839520524851986,\n",
       " -0.015631677538636694,\n",
       " -0.018207494117963154,\n",
       " -0.004239366377817523,\n",
       " -0.021111601903912806,\n",
       " -0.013964971487949186,\n",
       " 0.0031534824431134895,\n",
       " 0.0019508029744718582,\n",
       " -0.002995650508347993,\n",
       " 0.04734958694890699,\n",
       " 0.0011008778788669585,\n",
       " 0.008573431497399187,\n",
       " 0.00813781560890351,\n",
       " -0.010113871627745269,\n",
       " -0.002081803505938591,\n",
       " -0.009286832038116973,\n",
       " 0.013889212122008845,\n",
       " 0.024760676477834954,\n",
       " 0.03714732815246789,\n",
       " 0.010139124439284525,\n",
       " 0.008592371804545558,\n",
       " -0.03224822497185268,\n",
       " 0.012285639497153337,\n",
       " 0.005183201268552775,\n",
       " 0.010278017231056865,\n",
       " -0.01781607041683053,\n",
       " -0.016578668681568386,\n",
       " -0.010644187189327657,\n",
       " 0.03593517829742243,\n",
       " -0.013321016877456286,\n",
       " -0.031187593848687904,\n",
       " 0.02520260766469123,\n",
       " 0.04116257268466083,\n",
       " 0.03426847597202521,\n",
       " -0.005284213911693658,\n",
       " 0.005593564345509195,\n",
       " 0.00585556540844266,\n",
       " 0.005764022918874962,\n",
       " -0.015139241660024476,\n",
       " 0.025000581447086893,\n",
       " 0.002762059207642155,\n",
       " -0.020669672579701672,\n",
       " 0.0012239868485200132,\n",
       " -0.013699813707157992,\n",
       " 0.009842400411238617,\n",
       " 0.00843453963694942,\n",
       " 0.012052047963616856,\n",
       " 0.015543291301265439,\n",
       " -0.01800546976300396,\n",
       " -0.0010898297156108731,\n",
       " -0.016326136840885536,\n",
       " 0.009943413520040786,\n",
       " 0.055001281046236306,\n",
       " 0.021540906219338168,\n",
       " 0.018207494117963154,\n",
       " -0.0066668218744436,\n",
       " -0.004532933688005703,\n",
       " 0.014634178909981343,\n",
       " 0.04212219256166858,\n",
       " -0.02169242495121885,\n",
       " 0.027424881157177814,\n",
       " -0.030152216468384955,\n",
       " 0.006515303142562917,\n",
       " -0.004337222303100679,\n",
       " 0.0032481816505389163,\n",
       " -0.04439497353987882,\n",
       " 0.00038155875410040614,\n",
       " -0.008819649902366583,\n",
       " 0.016704933670587244,\n",
       " 0.03106132885966905,\n",
       " 0.020215116384059623,\n",
       " -0.0024511301820671115,\n",
       " 0.0013084269557384648,\n",
       " 0.00831458715232345,\n",
       " -0.011578552392151008,\n",
       " -0.006398507375794677,\n",
       " -0.0005547793100725345,\n",
       " 0.00872495022927987,\n",
       " 0.007733765967662549,\n",
       " 0.00416992044759264,\n",
       " -0.0017629829185498694,\n",
       " -0.6703186612238833,\n",
       " -0.012392965110348392,\n",
       " 0.023371756010692128,\n",
       " 0.0004419294697302852,\n",
       " 0.026717793120852915,\n",
       " 0.038687769214136546,\n",
       " -0.010315896914027036,\n",
       " -0.009305772345263344,\n",
       " -0.003980522032741786,\n",
       " 0.009381531711203685,\n",
       " -0.012784388811481012,\n",
       " 0.0039016059489437164,\n",
       " 0.004340379020958407,\n",
       " 0.019596416447751123,\n",
       " 0.020846445054444183,\n",
       " -0.01919236587518759,\n",
       " 0.007430728503901184,\n",
       " -0.028586523526499617,\n",
       " -0.015101361977054306,\n",
       " -0.0010266968718554816,\n",
       " -0.022361632373251006,\n",
       " 0.023359129139261213,\n",
       " 0.002468491897453976,\n",
       " -0.009425724829889313,\n",
       " 0.015404398509493098,\n",
       " -0.0066731353101590575,\n",
       " 0.003139277678414997,\n",
       " -0.02397783093821486,\n",
       " -0.00841560026112562,\n",
       " 0.022727802331521798,\n",
       " -0.025909693838370988,\n",
       " 0.007437041939616641,\n",
       " -0.0030729882332171986,\n",
       " -0.0009469917250083011,\n",
       " 0.04689503075326494,\n",
       " 0.009514110135937996,\n",
       " -0.004716018667141099,\n",
       " 0.030253229577187124,\n",
       " 0.02199546055233507,\n",
       " 0.0393948553878163,\n",
       " -0.009892906965639702,\n",
       " -0.010473729081623176,\n",
       " 0.004005774844281043,\n",
       " 0.015959966882614744,\n",
       " -0.02896532035620132,\n",
       " -0.007115064634370191,\n",
       " 0.01337152343185737,\n",
       " 0.020896950677522695,\n",
       " 0.014558419544041003,\n",
       " -0.014899336690772537,\n",
       " -0.008813336466651125,\n",
       " 0.00806205624296317,\n",
       " -0.0065089897068474605,\n",
       " -0.0010117028112772355,\n",
       " 0.005180045016356332,\n",
       " -0.007310776019275215,\n",
       " 0.02241213799632952,\n",
       " -0.03952112037683515,\n",
       " 0.017702432299242593,\n",
       " 0.004075221240167213,\n",
       " 0.013523042163738053,\n",
       " -0.01684382553103701,\n",
       " -0.006294338480457351,\n",
       " -0.0024953233007527394,\n",
       " -0.02548039138559077,\n",
       " 0.022210113641370325,\n",
       " -0.022790934826031225,\n",
       " -0.002075490303053777,\n",
       " 0.010379029408536463,\n",
       " -0.0199878382862386,\n",
       " 0.010997730276167536,\n",
       " 0.0140786105368597,\n",
       " 0.00487069411687951,\n",
       " 0.007323402890706129,\n",
       " 0.006385880970025049,\n",
       " 0.01726050297503146,\n",
       " 0.0024495520559688904,\n",
       " -0.017967589148711216,\n",
       " -0.012367712298809135,\n",
       " 0.007759018779201805,\n",
       " 0.006843593417863539,\n",
       " 0.005088502061127348,\n",
       " -0.023826312206334174,\n",
       " -0.003532279272815196,\n",
       " 0.024937448952577466,\n",
       " 0.00327027820988173,\n",
       " -0.009267892662293173,\n",
       " 0.012696002574109756,\n",
       " -0.002351696130685735,\n",
       " -0.007317089454990672,\n",
       " 0.025467764514159854,\n",
       " 0.040985803935208606,\n",
       " -0.005940794927956187,\n",
       " -0.02616222567905384,\n",
       " -0.017273129846462374,\n",
       " 0.011906842667451631,\n",
       " -0.012310892308692593,\n",
       " 0.007601187077266951,\n",
       " -0.006168073025777211,\n",
       " -0.020997963786324864,\n",
       " 0.0037942803357486616,\n",
       " -0.002642106955846829,\n",
       " 0.0019792127366994863,\n",
       " 0.006288025044741894,\n",
       " 0.01909135276638542,\n",
       " -0.007897911570974145,\n",
       " -0.012620243208169415,\n",
       " 0.01448266017810066,\n",
       " -0.0012760714126039978,\n",
       " -0.019103979637816335,\n",
       " 0.0015704280186719308,\n",
       " 0.008188322163304597,\n",
       " -0.002926204578123109,\n",
       " -0.006190169119458739,\n",
       " -0.002130731468580169,\n",
       " -0.024722797726187358,\n",
       " 0.0017282599534374273,\n",
       " 0.012891714424676067,\n",
       " 0.012658122891139587,\n",
       " -0.025227859544907916,\n",
       " -0.006338531599142979,\n",
       " -0.008541865250144474,\n",
       " 0.019710054565339065,\n",
       " -0.01907872775759965,\n",
       " -0.0077779586206868905,\n",
       " 0.01612411248592634,\n",
       " -0.026111718193330184,\n",
       " -0.028510764160559275,\n",
       " 0.015480157875433439,\n",
       " -0.024546025251444847,\n",
       " -0.007348655702245385,\n",
       " -0.005814529473276047,\n",
       " 0.01337152343185737,\n",
       " -0.010574741259102774,\n",
       " -0.00593448149224073,\n",
       " 0.009021674257325777,\n",
       " 0.032399743703733365,\n",
       " 0.01583370189359589,\n",
       " 0.016035726248555086,\n",
       " -0.009267892662293173,\n",
       " -0.013649307152756907,\n",
       " 0.013384150303288284,\n",
       " -0.027475386780256326,\n",
       " -0.00021859725467950693,\n",
       " 0.007954730629768115,\n",
       " -0.010309583478311578,\n",
       " -0.0018782003263892455,\n",
       " 0.005685107300738178,\n",
       " 0.008939602386992552,\n",
       " 0.005511492009514682,\n",
       " -0.009305772345263344,\n",
       " -0.014735191087460941,\n",
       " -0.004425608074810648,\n",
       " -0.00502852628447565,\n",
       " 0.008409286825410162,\n",
       " -0.002304346526973022,\n",
       " -0.007961044065483572,\n",
       " -0.00075167469700485,\n",
       " 0.005442046079289798,\n",
       " -0.0066731353101590575,\n",
       " -0.0033428808579643427,\n",
       " -0.0021907074780625102,\n",
       " -0.0075317411470420675,\n",
       " -0.011237635245419474,\n",
       " -0.001815067482633854,\n",
       " -0.023649539731591663,\n",
       " -0.004059438116539856,\n",
       " 0.022424764867760433,\n",
       " -0.009129000801843404,\n",
       " -0.0372483431239152,\n",
       " 0.008478732755635047,\n",
       " -0.0023295995713429217,\n",
       " -0.009198446732068289,\n",
       " -0.01116818931519459,\n",
       " 0.0005046676946496302,\n",
       " 0.0024448169791822976,\n",
       " -0.011957349221852716,\n",
       " -0.01755091356736191,\n",
       " -0.00864919086333953,\n",
       " -0.001983947580655436,\n",
       " 0.007702199254746549,\n",
       " 0.004984333165790022,\n",
       " -0.01171113081688532,\n",
       " -0.003573315440812452,\n",
       " 0.032627023664199534,\n",
       " 0.007197137436025989,\n",
       " 0.034394740961044064,\n",
       " 0.040076691543924514,\n",
       " -0.011969975161961058,\n",
       " -0.006231205520286638,\n",
       " 0.000886226419646206,\n",
       " 0.0006688128905076018,\n",
       " -0.00543888936143207,\n",
       " -0.003001963711232807,\n",
       " -0.0031818922053411173,\n",
       " -0.004880164270452696,\n",
       " 0.011572238956435553,\n",
       " 0.014596299227011174,\n",
       " 0.018321134098196235,\n",
       " 0.01337152343185737,\n",
       " 0.0045045241586087175,\n",
       " -0.018119107880591897,\n",
       " 0.008346154330900735,\n",
       " -0.016603922424430217,\n",
       " 0.014949843245173624,\n",
       " -0.04899103925673266,\n",
       " -0.010208571300831982,\n",
       " -0.01790445665420179,\n",
       " 0.012967473790616408,\n",
       " 0.019811067674141234,\n",
       " -0.007765332214917263,\n",
       " 0.0012255650910335558,\n",
       " -0.011490166154779755,\n",
       " -0.01818224223774647,\n",
       " 0.01633876371231645,\n",
       " 0.04237472253970629,\n",
       " -0.005912384932897916,\n",
       " 0.012696002574109756,\n",
       " -0.009968666331580044,\n",
       " -0.0037248341726931343,\n",
       " 0.00454871681163306,\n",
       " -0.006212265678801553,\n",
       " 0.005710360112277435,\n",
       " -0.021982835543549302,\n",
       " -0.0055998777812246514,\n",
       " 0.022172233027077583,\n",
       " 0.00968456917496505,\n",
       " 0.02616222567905384,\n",
       " -0.0030793014361020126,\n",
       " 0.003784810415006119,\n",
       " -0.036238215761183794,\n",
       " 0.0039710518791686005,\n",
       " -0.0009564616457508438,\n",
       " 0.017790818536613847,\n",
       " -0.003230820167982695,\n",
       " -0.017702432299242593,\n",
       " 0.030606772664027,\n",
       " -0.03204619875424834,\n",
       " 0.025152100178967577,\n",
       " 0.00027896798486130116,\n",
       " 0.005574624504024109,\n",
       " 0.01573268878479372,\n",
       " 0.009387845146919142,\n",
       " -0.01565692941885338,\n",
       " 0.02195758180068747,\n",
       " 0.02106109628083429,\n",
       " -0.0033397241401066143,\n",
       " -0.00019640213521513017,\n",
       " -0.004027871403623856,\n",
       " -0.003652231524610522,\n",
       " -0.021654544336926106,\n",
       " -0.010423222527222092,\n",
       " 0.004823344745997439,\n",
       " 0.010846212475609424,\n",
       " 0.0022775151236742583,\n",
       " -0.03795542929759496,\n",
       " 0.006490049865362375,\n",
       " 0.0054546724850594265,\n",
       " 0.0332583486092938,\n",
       " 0.0346725246819436,\n",
       " 0.01895246090593565,\n",
       " 0.008503985567174303,\n",
       " -0.0032671214920240014,\n",
       " -0.021250493764362572,\n",
       " 0.019116606509247246,\n",
       " 0.00821988841055931,\n",
       " -0.0019823694545572147,\n",
       " -0.015379145697953843,\n",
       " -0.001449686470996851,\n",
       " 0.006546869389817631,\n",
       " -0.011439660531701241,\n",
       " -0.004526620717951532,\n",
       " 0.0021922858369913746,\n",
       " -0.018927209025718966,\n",
       " 0.007784272056402347,\n",
       " -0.0020896950677522694,\n",
       " -0.016174618109004852,\n",
       " 0.008990108010071064,\n",
       " -0.0030161687087619424,\n",
       " 0.03285429989937541,\n",
       " -0.004662355860543571,\n",
       " -0.0126707497625705,\n",
       " 7.429199719709384e-06,\n",
       " 0.037702899319557254,\n",
       " 0.016060979991416913,\n",
       " -0.0153665197578455,\n",
       " -0.029975445856287586,\n",
       " -0.013182125017006517,\n",
       " -0.01386395931046959,\n",
       " 0.03368765106207402,\n",
       " 0.0027368061632722556,\n",
       " 0.011565925520720095,\n",
       " 0.007664320037437665,\n",
       " -0.009129000801843404,\n",
       " -0.01633876371231645,\n",
       " 0.011483852719064297,\n",
       " 0.029773419638683248,\n",
       " -0.019520657081810784,\n",
       " 0.013611428401109309,\n",
       " -0.014874083879233281,\n",
       " 0.020328756364292707,\n",
       " 0.008554492121575389,\n",
       " -0.029722914015604736,\n",
       " -0.0069887991796900506,\n",
       " 0.010480041586016061,\n",
       " -0.01572006377600795,\n",
       " -0.019066100886168735,\n",
       " -0.008971168634247266,\n",
       " -0.02090957754895361,\n",
       " -0.005795589631790962,\n",
       " -0.008586058368830102,\n",
       " -0.0012958003171381937,\n",
       " -0.01786657790255419,\n",
       " -0.007279209772020501,\n",
       " -0.022538402985348375,\n",
       " 0.013245257511515944,\n",
       " -0.015505411618295268,\n",
       " -0.002732071086485663,\n",
       " 0.020644420699484987,\n",
       " 0.012733882257079927,\n",
       " -0.005265274070208573,\n",
       " -0.014141743031369126,\n",
       " -0.014268008951710551,\n",
       " 0.003222928606169017,\n",
       " 0.09863866092671171,\n",
       " 0.004731802256429741,\n",
       " 0.018750436550976454,\n",
       " 0.009867654154100446,\n",
       " 0.027904689233036545,\n",
       " 0.009823461035414819,\n",
       " -0.024078844047017028,\n",
       " -0.0099939191431193,\n",
       " 0.008851216149621297,\n",
       " 0.013914464933548101,\n",
       " -0.01607360686284783,\n",
       " -0.014015478042350272,\n",
       " 0.008327214023754364,\n",
       " -0.0014623131095971222,\n",
       " 0.018384266592705662,\n",
       " 0.008718637724886985,\n",
       " -0.0033081578928519004,\n",
       " -0.0071340044758552755,\n",
       " -0.007386535385215556,\n",
       " -0.0029546143403507367,\n",
       " 0.005161105174871247,\n",
       " -0.017538286695930997,\n",
       " 0.011086116513538791,\n",
       " 0.03914232540977859,\n",
       " 0.020467648224742476,\n",
       " 0.004179390135504539,\n",
       " 0.012525544466405275,\n",
       " 0.007190824000310532,\n",
       " 0.0007571988368405534,\n",
       " -0.009299458909547887,\n",
       " -0.023750552840393836,\n",
       " 0.013017979413694921,\n",
       " -0.0030461568299184347,\n",
       " -0.011256575552565845,\n",
       " -0.022172233027077583,\n",
       " 0.006572122667018174,\n",
       " -0.014394274872051978,\n",
       " 0.023712674088746236,\n",
       " 0.02265204296558146,\n",
       " -0.003355507496564614,\n",
       " 0.030303735200265636,\n",
       " 0.027071338070337934,\n",
       " 0.005009586442990564,\n",
       " -0.0146594317215206,\n",
       " 0.011180816186625503,\n",
       " -0.02137676061602657,\n",
       " -0.02487431645806804,\n",
       " 0.022462643619408033,\n",
       " -0.005246334228723487,\n",
       " -0.01909135276638542,\n",
       " 0.036869544431568355,\n",
       " 0.012487664783435104,\n",
       " -0.025366751405357685,\n",
       " -0.02684405997251691,\n",
       " 0.0027068180421157633,\n",
       " 0.00506640596744582,\n",
       " -0.03310682987741312,\n",
       " -0.01969742769390815,\n",
       " -0.022462643619408033,\n",
       " -0.006243832391717552,\n",
       " -0.02204596803805873,\n",
       " -0.03217246746855748,\n",
       " -0.006373254564255421,\n",
       " -0.01602309937712417,\n",
       " -7.447695658659662e-05,\n",
       " -0.04838496432920993,\n",
       " -0.029167344711160517,\n",
       " 0.008914348644130723,\n",
       " -0.013321016877456286,\n",
       " 0.001234245948726988,\n",
       " -0.018169615366315554,\n",
       " -0.01837163972127475,\n",
       " -0.015884207516674402,\n",
       " -0.008977482069962722,\n",
       " 0.019444897715870442,\n",
       " 0.009349965463948971,\n",
       " 0.011464913343240497,\n",
       " 0.0008980638205743843,\n",
       " 0.021742930574297364,\n",
       " 0.027626905512137007,\n",
       " -0.010391656279967378,\n",
       " -0.0028551800561387175,\n",
       " 0.01688170614532975,\n",
       " 0.0034849296691024825,\n",
       " -0.018359012849843835,\n",
       " 0.011376527105869241,\n",
       " -0.004589753212460959,\n",
       " -0.0029546143403507367,\n",
       " 0.0035859420794127233,\n",
       " -0.0007137950140346794,\n",
       " 0.009653002927710336,\n",
       " -0.009634062620563965,\n",
       " 0.014356395189081807,\n",
       " 0.01116818931519459,\n",
       " 0.023674793474453493,\n",
       " 0.003911076102516902,\n",
       " 0.003847943142346189,\n",
       " 0.017184743609091117,\n",
       " -0.002296454965159344,\n",
       " -0.005707203394419706,\n",
       " 0.025253113287769746,\n",
       " 0.008971168634247266,\n",
       " -0.017222622360738717,\n",
       " -0.002468491897453976,\n",
       " 0.02669254124063623,\n",
       " 0.01569481003314612,\n",
       " 0.020177237632412026,\n",
       " 0.01386395931046959,\n",
       " -0.01969742769390815,\n",
       " -0.002858336773996446,\n",
       " 0.032904807385099065,\n",
       " -0.032349236218009704,\n",
       " 0.02805620796491723,\n",
       " 0.002234900596748138,\n",
       " 0.006849906853578996,\n",
       " 0.02195758180068747,\n",
       " -0.02712184369341645,\n",
       " 0.014634178909981343,\n",
       " -0.0014189092867912482,\n",
       " -0.010214883805224867,\n",
       " -0.007260269930535416,\n",
       " -0.01544227819246327,\n",
       " 0.04169289010888837,\n",
       " 0.023397009753553955,\n",
       " -0.014672058592951514,\n",
       " -0.01593471500239806,\n",
       " 0.013472535609336969,\n",
       " -0.006187012867262296,\n",
       " -0.016818573650820325,\n",
       " -0.01386395931046959,\n",
       " 0.0008096779324490934,\n",
       " 0.03348562856975997,\n",
       " -0.016856452402467925,\n",
       " -0.021578784970985768,\n",
       " -0.03515233462044748,\n",
       " 0.01612411248592634,\n",
       " 0.013687186835727078,\n",
       " 0.015379145697953843,\n",
       " -0.011389153977300157,\n",
       " -0.011395467413015612,\n",
       " -0.009754015105189934,\n",
       " -0.005792432913933233,\n",
       " 0.0003397332902233963,\n",
       " -0.014684685464382428,\n",
       " -0.007948417194052659,\n",
       " -0.0353291033698997,\n",
       " -0.02342226163377064,\n",
       " -0.018927209025718966,\n",
       " 0.006496363301077833,\n",
       " 0.03194518750809132,\n",
       " -0.035051319649000164,\n",
       " -0.003737460811293406,\n",
       " -0.007298149613505587,\n",
       " -0.0017172116737660204,\n",
       " 0.0016122534825489406,\n",
       " -0.025543523880100196,\n",
       " 0.005378913119119085,\n",
       " 0.00878808365511187,\n",
       " 0.01643977682111862,\n",
       " 0.040733270231880614,\n",
       " 0.011149249008048218,\n",
       " 0.003702737613350321,\n",
       " 0.019495403338948954,\n",
       " 0.012576050089483789,\n",
       " -0.006742581240383941,\n",
       " -0.0062217358323747385,\n",
       " -0.007607500512982409,\n",
       " 0.013712440578588907,\n",
       " -0.011534359273465382,\n",
       " 0.020682299451132584,\n",
       " 0.004734958508626185,\n",
       " -0.005666167459253093,\n",
       " 0.03282904615651358,\n",
       " 0.01854841219601726,\n",
       " -0.028106715450640883,\n",
       " 0.009949726955756244,\n",
       " 0.014874083879233281,\n",
       " -0.00818200872758914,\n",
       " -0.020745431945642014,\n",
       " -0.007108751198654733,\n",
       " 0.018308507226765323,\n",
       " 0.004848597557536696,\n",
       " 0.009551989818908167,\n",
       " 0.0146594317215206,\n",
       " 0.014886709819341624,\n",
       " 0.009678255739249592,\n",
       " 0.021048469409403376,\n",
       " -0.013497789352198798,\n",
       " 0.024508146499797247,\n",
       " -0.009046928000187606,\n",
       " 0.01654078992992079,\n",
       " -0.023750552840393836,\n",
       " -0.00720345040608016,\n",
       " 0.0008096779324490934,\n",
       " 0.0073991622566464705,\n",
       " 0.0006692074802398178,\n",
       " -0.017424648578343055,\n",
       " 0.006685761715928685,\n",
       " -0.0011861071655498425,\n",
       " 0.013889212122008845,\n",
       " 0.024407133390995078,\n",
       " 0.01983631955435792,\n",
       " -0.0173362623409718,\n",
       " 0.005947107898010358,\n",
       " -0.006250145361771723,\n",
       " 0.021212615012714976,\n",
       " -0.018359012849843835,\n",
       " -0.03388967727967836,\n",
       " 0.009892906965639702,\n",
       " -0.03340986734117449,\n",
       " -0.0201141051379026,\n",
       " -0.02219748676993941,\n",
       " -0.03396543850826385,\n",
       " -0.022109100532568156,\n",
       " 0.0043687885503553925,\n",
       " 0.014179622714339295,\n",
       " -0.027248108682435303,\n",
       " 0.01462155203855043,\n",
       " 0.011351274294329985,\n",
       " -0.005921855086471102,\n",
       " 0.0009485700839371654,\n",
       " 0.018965087777366565,\n",
       " 0.01805597538608247,\n",
       " 0.007601187077266951,\n",
       " 0.006104940065606498,\n",
       " 0.02137676061602657,\n",
       " 0.0036837977718652353,\n",
       " -0.03429372598959675,\n",
       " 0.023801058463472347,\n",
       " 0.0008538708765117389,\n",
       " 0.009659315432103221,\n",
       " -0.001300535277509465,\n",
       " 0.035379610855623356,\n",
       " -0.0029467225457064155,\n",
       " -0.004299342620130508,\n",
       " 0.02166717120835702,\n",
       " -0.008017863124277543,\n",
       " -0.005053779096014906,\n",
       " -0.01958378957632021,\n",
       " 0.025404632019650427,\n",
       " -0.004978019730074564,\n",
       " 0.01116818931519459,\n",
       " -0.014608926098442087,\n",
       " -0.02301821292385225,\n",
       " -0.01212149389384174,\n",
       " 0.005754553230963063,\n",
       " -0.014962469185281966,\n",
       " 0.009305772345263344,\n",
       " -0.02434400089648565,\n",
       " -0.000847557615419264,\n",
       " -0.02195758180068747,\n",
       " 0.004166763729734911,\n",
       " -0.025316245782279173,\n",
       " 0.04060700524286176,\n",
       " -0.03189468002236766,\n",
       " 0.012140434200988112,\n",
       " -0.0011253418601877474,\n",
       " -0.019899453911512488,\n",
       " -0.0013510415990799069,\n",
       " -0.014987722928143793,\n",
       " -0.001134022601465858,\n",
       " 0.016780693036527582,\n",
       " -0.03368765106207402,\n",
       " -0.019899453911512488,\n",
       " 0.0067236413988988565,\n",
       " -0.005262117352350844,\n",
       " -0.00552411841528431,\n",
       " 0.009059553940295948,\n",
       " -0.009400471087027485,\n",
       " 0.024710170854756443,\n",
       " -0.026288490668072696,\n",
       " 0.0007469397366335786,\n",
       " -0.01593471500239806,\n",
       " 0.00548623873231414,\n",
       " -0.011843710172942204,\n",
       " -0.0007398372960766717,\n",
       " -0.011155562443763676,\n",
       " -0.019735308308200892,\n",
       " 0.004378258703928578,\n",
       " -0.009627749184848508,\n",
       " 0.018586290947664858,\n",
       " 0.007721139096231635,\n",
       " 0.004204643412705081,\n",
       " 0.0013139510955741684,\n",
       " -0.015997847496907486,\n",
       " 0.0016888019115383925,\n",
       " -0.014242756140171295,\n",
       " -0.001240559151611802,\n",
       " -0.006104940065606498,\n",
       " 0.00945097764142857,\n",
       " 0.0024211422937412625,\n",
       " -0.0002643685140152711,\n",
       " -0.0016446090256834077,\n",
       " -0.004611849771803772,\n",
       " 0.027424881157177814,\n",
       " -0.008977482069962722,\n",
       " 0.03464727093908177,\n",
       " 0.052071917654779684,\n",
       " -0.03353613233019334,\n",
       " 0.01532864007487533,\n",
       " -0.011218695869595674,\n",
       " 0.007670633007491836,\n",
       " -0.038056440543751985,\n",
       " 0.005685107300738178,\n",
       " -0.0015309699767728957,\n",
       " -0.008497672131458847,\n",
       " 0.0014386383077407657,\n",
       " 0.023460142248063382,\n",
       " -0.010334836289850836,\n",
       " 0.0004273300279880855,\n",
       " 0.011218695869595674,\n",
       " 0.0186241715619576,\n",
       " 0.0016793319907958497,\n",
       " -0.022109100532568156,\n",
       " 0.005167418144925418,\n",
       " -0.002017092419669657,\n",
       " 0.03333410983787929,\n",
       " -0.030430002051929635,\n",
       " -0.039293844141659276,\n",
       " 0.022222738650156094,\n",
       " 0.006906726378034252,\n",
       " -0.004441391198438005,\n",
       " 0.006553182825533088,\n",
       " -0.01469731140449077,\n",
       " 0.014179622714339295,\n",
       " 0.004416137921237463,\n",
       " 0.022487897362269863,\n",
       " 0.005233707822953859,\n",
       " -0.02423036277889771,\n",
       " -0.028712790378163613,\n",
       " -0.04032922152196222,\n",
       " 0.02566978886911905,\n",
       " -0.011969975161961058,\n",
       " -0.007380222415161385,\n",
       " -0.009457291077144027,\n",
       " -0.015619050667205779,\n",
       " -0.02108635002369612,\n",
       " 0.014583672355580259,\n",
       " 0.006685761715928685,\n",
       " -0.005745083077389877,\n",
       " 0.015025602611113964,\n",
       " 0.027576399889058495,\n",
       " 0.0019634296130721296,\n",
       " -0.005688263552934621,\n",
       " -0.01101035714759845,\n",
       " -0.012007854844931228,\n",
       " -0.002556877669163945,\n",
       " -0.017487781072852482,\n",
       " -0.019204992746618504,\n",
       " -0.016755441156310898,\n",
       " -0.029167344711160517,\n",
       " 0.01329576406591703,\n",
       " 0.025000581447086893,\n",
       " 0.014533166732501747,\n",
       " -0.007020365426944764,\n",
       " 0.014722565147352599,\n",
       " -0.013712440578588907,\n",
       " 0.0018450556037903462,\n",
       " -0.0025868657903204374,\n",
       " 0.010909344970118853,\n",
       " 0.014962469185281966,\n",
       " -0.01923024648948033,\n",
       " -0.007519114275611153,\n",
       " 0.023295996644751786,\n",
       " 0.0025000581447086894,\n",
       " 0.015707436904577037,\n",
       " -0.01569481003314612,\n",
       " -0.021982835543549302,\n",
       " 0.015025602611113964,\n",
       " -0.016502909315628048,\n",
       " -0.006168073025777211,\n",
       " -0.025644536988902365,\n",
       " -0.020530780719251903,\n",
       " -0.009040614564472148,\n",
       " 0.033586639815916995,\n",
       " -0.009836087906845732,\n",
       " 0.009192133296352831,\n",
       " 0.009634062620563965,\n",
       " 0.003813220177233747,\n",
       " 0.0040120882799964995,\n",
       " -0.024899570200929866,\n",
       " -0.014810950453401283,\n",
       " -0.0029056863777091593,\n",
       " 0.0037406172963204915,\n",
       " 0.018750436550976454,\n",
       " -0.0004068118566779663,\n",
       " -0.03310682987741312,\n",
       " 0.0015601689184649558,\n",
       " -0.013990224299488443,\n",
       " 0.022576283599641117,\n",
       " -0.002829927011768818,\n",
       " 0.0026231671143617436,\n",
       " -0.0013904995245636203,\n",
       " 0.0037784969792906617,\n",
       " -0.015126614788593562,\n",
       " -0.0048612244289676105,\n",
       " -0.03366240104450248,\n",
       " -0.02420510903603588,\n",
       " 0.008301961212215108,\n",
       " -0.0068183406063242824,\n",
       " -0.023662166603022578,\n",
       " 0.02495007582400838,\n",
       " 0.00029218642074840535,\n",
       " -0.01636401745517828,\n",
       " -0.016136739357357256,\n",
       " -0.0014702046714108006,\n",
       " 0.01304323315655675,\n",
       " 0.0019239715711730945,\n",
       " 0.004479270881408175,\n",
       " 0.0071340044758552755,\n",
       " 0.0055904080933127515,\n",
       " -0.0022775151236742583,\n",
       " 0.0160104743683384,\n",
       " -0.028788549744103956,\n",
       " 0.02072018006542533,\n",
       " -0.010947224653089022,\n",
       " -0.011332334918506186,\n",
       " -0.0015601689184649558,\n",
       " -0.0011450708811372647,\n",
       " 0.00621857911451701,\n",
       " -0.026187477559270523,\n",
       " -0.004974863477878122,\n",
       " -0.019495403338948954,\n",
       " 0.027071338070337934,\n",
       " -0.015151867600132818,\n",
       " -0.023371756010692128,\n",
       " -0.015707436904577037,\n",
       " -0.009867654154100446,\n",
       " -0.004615006489661501,\n",
       " 0.03186943000479612,\n",
       " -0.032930061127960895,\n",
       " -0.02270254858865997,\n",
       " 0.0037311473755779487,\n",
       " 0.020328756364292707,\n",
       " -0.014356395189081807,\n",
       " 0.01450791392096249,\n",
       " 0.22343954380718697,\n",
       " -0.0126896891383943,\n",
       " 0.008068369678678628,\n",
       " 0.01532864007487533,\n",
       " -0.011553299580611753,\n",
       " 0.013472535609336969,\n",
       " 0.018927209025718966,\n",
       " -0.02241213799632952,\n",
       " 0.011723757688316235,\n",
       " 0.023384382882123043,\n",
       " -0.003964738909114429,\n",
       " -0.001786657720406226,\n",
       " -0.023990457809645774,\n",
       " 0.003013011990904214,\n",
       " 0.007304463049221044,\n",
       " 0.001684066951167121,\n",
       " -0.017513034815714312,\n",
       " -0.00392370250828653,\n",
       " -0.020934831291815437,\n",
       " -0.01861154469052669,\n",
       " -0.013055859096665092,\n",
       " -0.0006313278554773079,\n",
       " -0.022917199815050082,\n",
       " -0.0022206955992190025,\n",
       " 0.013358896560426457,\n",
       " 0.020227743255490538,\n",
       " -0.030581520783810316,\n",
       " -0.010669440000866915,\n",
       " -0.0047286455385720134,\n",
       " 0.01633876371231645,\n",
       " -0.014065983665428784,\n",
       " -0.01095353808880448,\n",
       " 0.02342226163377064,\n",
       " -0.02327074290188996,\n",
       " 0.008926975515561637,\n",
       " -0.01743727544977397,\n",
       " -0.005713516830135163,\n",
       " -0.019495403338948954,\n",
       " 0.010195944429401067,\n",
       " 0.011565925520720095,\n",
       " 0.006900412942318795,\n",
       " -0.0036048819208978084,\n",
       " 0.01825800160368681,\n",
       " -0.015189747283102989,\n",
       " -0.0036743278511226925,\n",
       " 0.04217270004739224,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9631510802407727"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7702031204123162"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding1, embedding3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759053971445477"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embedding2, embedding3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorstores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Vector DB**  | **Best For**                      | **Persistence**  | **Metadata Filtering** | **Cloud / Local** |\n",
    "|---------------|--------------------------------|---------------|------------------|----------------|\n",
    "| **Chroma**   | RAG, fast prototyping        | ✅ Yes       | ✅ Yes          | Local / Cloud  |\n",
    "| **FAISS**    | Large-scale local search     | ❌ No (manual) | ❌ No          | Local         |\n",
    "| **Pinecone** | Cloud-scale search          | ✅ Yes (Cloud) | ✅ Yes          | Cloud         |\n",
    "| **Weaviate** | Hybrid search (text + vector) | ✅ Yes       | ✅ Yes          | Local / Cloud  |\n",
    "| **Milvus**   | Distributed vector search    | ✅ Yes       | ✅ Yes          | Local / Cloud  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'docs/chroma/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma  # remove old database files if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty text chunks\n",
    "documents = [doc for doc in splits if doc.page_content.strip()]\n",
    "# Remove exact duplicate chunks\n",
    "unique_documents = list({doc.page_content: doc for doc in documents}.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total valid documents: 1211\n",
      "First document content: Aurélien Géron\n",
      "Hands-On  \n",
      "Machine Learning  \n",
      "with Scikit-Learn  \n",
      "& TensorFlow  \n",
      "CONCEPTS, TOOLS, AND TECHNIQUES  \n",
      "TO BUILD INTELLIGENT SYSTEMS\n",
      "\u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000 \u0000w\u0000w\u0000w\u0000\n",
      "First document metadata: {'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'creationdate': '2017-03-10T21:55:34+00:00', 'author': 'Aurélien Géron', 'moddate': '2017-05-16T09:54:54+08:00', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'trapped': '/False', 'source': 'docs/Geron2017.pdf', 'total_pages': 564, 'page': 0, 'page_label': 'Cover'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total valid documents: {len(documents)}\")\n",
    "print(f\"First document content: {documents[0].page_content[:200]}\")  # Print first 200 characters\n",
    "print(f\"First document metadata: {documents[0].metadata}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Surrogate Unicode Characters\n",
    "import unicodedata\n",
    "from langchain.schema import Document\n",
    "\n",
    "def clean_text(text):\n",
    "    return unicodedata.normalize(\"NFKD\", text).encode(\"utf-8\", \"ignore\").decode(\"utf-8\")\n",
    "\n",
    "documents = [\n",
    "    Document(page_content=clean_text(doc.page_content), metadata=doc.metadata)\n",
    "    for doc in documents\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "\n",
    "# try persist_directory=None if you get tenant error. It can also work in-memory mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1211\n",
      "[Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 1, 'page_label': '2', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Machine Learning Yearning is a\\n \\n \\ndeeplearning.ai project.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© 2018 Andrew Ng. All Rights Reserved.\\n \\n \\n \\n \\nPage 2\\nMachine Learning Yearning-Draft\\nAndrew Ng'), Document(metadata={'author': 'Aurélien Géron', 'creationdate': '2017-03-10T21:55:34+00:00', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'moddate': '2017-05-16T09:54:54+08:00', 'page': 25, 'page_label': '4', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'source': 'docs/Geron2017.pdf', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'total_pages': 564, 'trapped': '/False'}, page_content='If you already know all the Machine Learning basics, you may want\\nto skip directly to Chapter 2 . If you are not sure, tr\\ny to answer all\\nthe questions listed at the end of the chapter before moving on.\\nWhat Is Machine Learning?\\nMachine Learning is the science (and art) of programming computers so they can\\nlearn from data.\\nHere is a slightly more general definition:\\n[Machine Learning is the] field of study that gives computers the ability to learn\\nwithout being explicitly programmed.\\n—Arthur Samuel, 1959\\nAnd a more engineering-oriented one:\\nA computer program is said to learn from experience E with respect to some task T\\nand some performance measure P , if its performance on T, as measured by P , improves\\nwith experience E.\\n—Tom Mitchell, 1997\\nFor example, your spam filter is a Machine Learning program that can learn to flag\\nspam given examples of spam emails (e.g., flagged by users) and examples of regular\\n(nonspam, also called “ham”) emails. The examples that the system uses to learn are\\ncalled the training set. Each training example is called a training instance (or sample).\\nIn this case, the task T is to flag spam for new emails, the experience E is the training\\ndata, and the performance measure P needs to be defined; for example, you can use\\nthe ratio of correctly classified emails. This particular performance measure is called\\naccuracy and it is often used in classification tasks.\\nIf you just download a copy of Wikipedia, your computer has a lot more data, but it is'), Document(metadata={'author': 'Aurélien Géron', 'creationdate': '2017-03-10T21:55:34+00:00', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'moddate': '2017-05-16T09:54:54+08:00', 'page': 14, 'page_label': 'xiii', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'source': 'docs/Geron2017.pdf', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'total_pages': 564, 'trapped': '/False'}, page_content='videos, beating the world champion at the game of Go. Before you know it, it will be\\ndriving your car.\\nMachine Learning in Your Projects\\nSo naturally you are excited about Machine Learning and you would love to join the\\nparty!\\nPerhaps you would like to give your homemade robot a brain of its own? Make it rec‐\\nognize faces? Or learn to walk around?\\nxiii\\n\\x00D\\x00o\\x00w\\x00n\\x00l\\x00o\\x00a\\x00d\\x00 \\x00f\\x00r\\x00o\\x00m\\x00 \\x00f\\x00i\\x00n\\x00e\\x00l\\x00y\\x00b\\x00o\\x00o\\x00k\\x00 \\x00w\\x00w\\x00w\\x00.\\x00f\\x00i\\x00n\\x00e\\x00l\\x00y\\x00b\\x00o\\x00o\\x00k\\x00.\\x00c\\x00o\\x00m')]\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())  #tells us how many document chunks have been embedded and indexed in Chroma\n",
    "print(vectordb.similarity_search(\"What is AI?\", k=3))  # Test retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 91, 'page_label': '92', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'), Document(metadata={'author': 'Aurélien Géron', 'creationdate': '2017-03-10T21:55:34+00:00', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'moddate': '2017-05-16T09:54:54+08:00', 'page': 277, 'page_label': '256', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'source': 'docs/Geron2017.pdf', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'total_pages': 564, 'trapped': '/False'}, page_content='4 In the context of Machine Learning, the phrase “neural networks” generally refers to ANNs, not BNNs.\\n5 Drawing of a cortical lamination by S. Ramon y Cajal (public domain). Reproduced from https://en.w ikipe\\ndia.org/wiki/Cerebral_cortex.\\nworks (BNN)4 is still the subject of active research, but some parts of the brain ha ve\\nbeen mapped, and it seems tha\\nt neurons are often organized in consecutive layers, as \\nshown in Figure 10-2.\\nFigure 10-2. Multiple layers in a biological neural network (human cortex)5\\nLogical Computations with Neurons\\nWarren McCulloch and W\\nalter Pitts proposed a very simple model of the biological\\nneuron, which later became known as an artificial neuron: it has one or more binar y\\n(on/off) in\\nputs and one binary output. The artificial neuron simply activates its out‐\\nput when more than a certain number of its inputs are active. McCulloch and Pitts\\nshowed that even with such a simplified model it is possible to build a network of\\nartificial neurons that computes any logical proposition you want. For example, let’s\\nbuild a few ANNs that perform various logical computations (see Figure 10-3),\\nassuming that a neuron is activated when at least two of its inputs are active.\\nFigure 10-3. ANNs performing simple logical computations\\n256 | Chapter 10: Introduction to Artificial Neural Networks\\n\\x00D\\x00o\\x00w\\x00n\\x00l\\x00o\\x00a\\x00d\\x00 \\x00f\\x00r\\x00o\\x00m\\x00 \\x00f\\x00i\\x00n\\x00e\\x00l\\x00y\\x00b\\x00o\\x00o\\x00k\\x00 \\x00w\\x00w\\x00w\\x00.\\x00f\\x00i\\x00n\\x00e\\x00l\\x00y\\x00b\\x00o\\x00o\\x00k\\x00.\\x00c\\x00o\\x00m'), Document(metadata={'author': 'Aurélien Géron', 'creationdate': '2017-03-10T21:55:34+00:00', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'moddate': '2017-05-16T09:54:54+08:00', 'page': 374, 'page_label': '353', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'source': 'docs/Geron2017.pdf', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'total_pages': 564, 'trapped': '/False'}, page_content='CHAPTER 13\\nConvolutional Neural Networks\\nAlthough IBM’s Deep Blue supercom\\nputer beat the chess world champion Garry Kas‐\\nparov back in 1996, until quite recently computers were unable to reliably perform\\nseemingly trivial tasks such as detecting a puppy in a picture or recognizing spoken\\nwords. Why are these tasks so effortless to us humans? The answer lies in the fact that\\nperception largely takes place outside the realm of our consciousness, within special‐\\nized visual, auditory, and other sensory modules in our brains. By the time sensory\\ninformation reaches our consciousness, it is already adorned with high-level features;\\nfor example, when you look at a picture of a cute puppy, you cannot choose not to see\\nthe puppy, or not to notice its cuteness. Nor can you explain how you recognize a cute\\npuppy; it’s just obvious to you. Thus, we cannot trust our subjective experience: per‐\\nception is not trivial at all, and to understand it we must look at how the sensory\\nmodules work.\\nConvolutional neural networks (CNNs) emerged from the study of the brain’s visual\\ncortex, and they have been used in image recognition since the 1980s. In the last few\\nyears, thanks to the increase in computational power, the amount of available training\\ndata, and the tricks presented in Chapter 11 for training deep nets, CNNs have man‐\\naged to achieve superhuman performance on some complex visual tasks. They power\\nimage search services, self-driving cars, automatic video classification systems, and')]\n"
     ]
    }
   ],
   "source": [
    "docs_ss= vectordb.similarity_search(\"What are neural networks?\", k=3)\n",
    "print(docs_ss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ss[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 **Result 1:**\n",
      "📄 Source: docs/NG2018.pdf, Page: 91\n",
      "📝 Content:\n",
      "Neural networks are commonly used in end-to-end learning systems. The term “end-\n",
      "to-end”   refers to the fact that we are asking the learning algorithm to go\n",
      "directly from the input to   the desired output. I.e., the learning algorithm\n",
      "directly connects the “input end” of the   system to the “output end.”   In\n",
      "problems where data is abundant, end-to-end systems have been remarkably\n",
      "successful.   But they are not always a good choice. The next few chapters will\n",
      "give more examples of   end-to-end systems as well as give advice on when you\n",
      "should and should not use them.                       Page 92 Machine Learning\n",
      "Yearning-Draft Andrew Ng\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 **Result 2:**\n",
      "📄 Source: docs/Geron2017.pdf, Page: 277\n",
      "📝 Content:\n",
      "4 In the context of Machine Learning, the phrase “neural networks” generally\n",
      "refers to ANNs, not BNNs. 5 Drawing of a cortical lamination by S. Ramon y Cajal\n",
      "(public domain). Reproduced from https://en.w ikipe\n",
      "dia.org/wiki/Cerebral_cortex. works (BNN)4 is still the subject of active\n",
      "research, but some parts of the brain ha ve been mapped, and it seems tha t\n",
      "neurons are often organized in consecutive layers, as  shown in Figure 10-2.\n",
      "Figure 10-2. Multiple layers in a biological neural network (human cortex)5\n",
      "Logical Computations with Neurons Warren McCulloch and W alter Pitts proposed a\n",
      "very simple model of the biological neuron, which later became known as an\n",
      "artificial neuron: it has one or more binar y (on/off) in puts and one binary\n",
      "output. The artificial neuron simply activates its out‐ put when more than a\n",
      "certain number of its inputs are active. McCulloch and Pitts showed that even\n",
      "with such a simplified model it is possible to build a network of artificial\n",
      "neurons that computes any logical proposition you want. For example, let’s build\n",
      "a few ANNs that perform various logical computations (see Figure 10-3), assuming\n",
      "that a neuron is activated when at least two of its inputs are active. Figure\n",
      "10-3. ANNs performing simple logical computations 256 | Chapter 10: Introduction\n",
      "to Artificial Neural Networks \u0000D\u0000o\u0000w\u0000n\u0000l\u0000o\u0000a\u0000d\u0000 \u0000f\u0000r\u0000o\u0000m\u0000 \u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000\n",
      "\u0000w\u0000w\u0000w\u0000.\u0000f\u0000i\u0000n\u0000e\u0000l\u0000y\u0000b\u0000o\u0000o\u0000k\u0000.\u0000c\u0000o\u0000m\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "🔹 **Result 3:**\n",
      "📄 Source: docs/Geron2017.pdf, Page: 374\n",
      "📝 Content:\n",
      "CHAPTER 13 Convolutional Neural Networks Although IBM’s Deep Blue supercom puter\n",
      "beat the chess world champion Garry Kas‐ parov back in 1996, until quite\n",
      "recently computers were unable to reliably perform seemingly trivial tasks such\n",
      "as detecting a puppy in a picture or recognizing spoken words. Why are these\n",
      "tasks so effortless to us humans? The answer lies in the fact that perception\n",
      "largely takes place outside the realm of our consciousness, within special‐ ized\n",
      "visual, auditory, and other sensory modules in our brains. By the time sensory\n",
      "information reaches our consciousness, it is already adorned with high-level\n",
      "features; for example, when you look at a picture of a cute puppy, you cannot\n",
      "choose not to see the puppy, or not to notice its cuteness. Nor can you explain\n",
      "how you recognize a cute puppy; it’s just obvious to you. Thus, we cannot trust\n",
      "our subjective experience: per‐ ception is not trivial at all, and to understand\n",
      "it we must look at how the sensory modules work. Convolutional neural networks\n",
      "(CNNs) emerged from the study of the brain’s visual cortex, and they have been\n",
      "used in image recognition since the 1980s. In the last few years, thanks to the\n",
      "increase in computational power, the amount of available training data, and the\n",
      "tricks presented in Chapter 11 for training deep nets, CNNs have man‐ aged to\n",
      "achieve superhuman performance on some complex visual tasks. They power image\n",
      "search services, self-driving cars, automatic video classification systems, and\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "\n",
    "# Print formatted results\n",
    "for i, doc in enumerate(docs_ss):\n",
    "    print(f\"\\n🔹 **Result {i+1}:**\")\n",
    "    print(f\"📄 Source: {doc.metadata.get('source', 'Unknown')}, Page: {doc.metadata.get('page', 'N/A')}\")\n",
    "    print(\"📝 Content:\")\n",
    "    print(textwrap.fill(doc.page_content, width=80))  # Wrap text to 80 characters\n",
    "    print(\"-\" * 100)  # Divider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "Retrieval is the centerpiece of our retrieval augmented generation (RAG) flow. \n",
    "Let's get our vectorDB from before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/MMR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/LLM_retrieval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/compression.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
    "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
    "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "smalldb = Chroma.from_texts(texts, embedding=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(metadata={}, page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.similarity_search(question, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Diversity: Maximum marginal relevance\n",
    "\n",
    "Last class we introduced one problem: how to enforce diversity in the search results.\n",
    " \n",
    "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
       " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_mmr = vectordb.max_marginal_relevance_search(\"What are neural networks?\", k=2, fetch_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are commonly used in end-to-end learning systems. The term “end-to-end”\\n \\nrefers to the fact that we are asking the learning algorithm to go directly from the input to\\n \\nthe desired output. I.e., the learning algorithm directly connects the “input end” of the\\n \\nsystem to the “output end.”\\n \\nIn problems where data is abundant, end-to-end systems have been remarkably successful.\\n \\nBut they are not always a good choice. The next few chapters will give more examples of\\n \\nend-to-end systems as well as give advice on when you should and should not use them.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\nPage 92\\nMachine Learning Yearning-Draft\\nAndrew Ng'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_mmr[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Specificity: working with metadata\n",
    "\n",
    "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
    "\n",
    "To address this, many vectorstores support operations on `metadata`.\n",
    "\n",
    "`metadata` provides context for each embedded chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about deep learning in NG book?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = vectordb.similarity_search(\n",
    "    question,\n",
    "    k=3,\n",
    "    filter={\"source\":\"docs/NG2018.pdf\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creationdate': '', 'creator': 'PyPDF', 'page': 54, 'page_label': '55', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}\n",
      "{'creationdate': '', 'creator': 'PyPDF', 'page': 47, 'page_label': '48', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}\n",
      "{'creationdate': '', 'creator': 'PyPDF', 'page': 8, 'page_label': '9', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}\n"
     ]
    }
   ],
   "source": [
    "for d in docs:\n",
    "    print(d.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Specificity: working with metadata using self-query retriever\n",
    "\n",
    "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
    "\n",
    "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
    " \n",
    "1. The `query` string to use for vector search\n",
    "2. A metadata filter to pass in as well\n",
    "\n",
    "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The lecture the chunk is from, should be one of `docs/NG2018.pdf`, `docs/Zheng2018.pdf`, or `docs/Geron2017.pdf`\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"page\",\n",
    "        description=\"The page from the lecture\",\n",
    "        type=\"integer\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_17578/1248247315.py:5: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
      "  llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
    "\n",
    "\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
    "\n",
    "document_content_description = \"AI books\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vectordb,\n",
    "    document_content_description,\n",
    "    metadata_field_info,\n",
    "    structured_query_translator=ChromaTranslator(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what did they say about artifical intelligence in the first page?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 68, 'page_label': '69', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='human-level performance.\\n \\n \\nThere are many important machine learning applications where machines surpass human\\n \\nlevel performance. For example, machines are better at predicting movie ratings, how long it\\n \\ntakes for a delivery car to drive somewhere, or whether to approve loan applications. Only a\\n \\nsubset of techniques apply once humans have a hard time identifying examples that the\\n \\nalgorithm is clearly getting wrong. Consequently, progress is usually slower on problems\\n \\nwhere machines already surpass human-level performance, while progress is faster when\\n \\nmachines are still trying to catch up to humans.\\n \\n \\n \\n \\n \\nPage 69\\nMachine Learning Yearning-Draft\\nAndrew Ng'),\n",
       " Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 1, 'page_label': '2', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Machine Learning Yearning is a\\n \\n \\ndeeplearning.ai project.\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n© 2018 Andrew Ng. All Rights Reserved.\\n \\n \\n \\n \\nPage 2\\nMachine Learning Yearning-Draft\\nAndrew Ng'),\n",
       " Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 89, 'page_label': '90', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='End-to-end\\n \\ndeep learning\\n \\n  \\n  \\n  \\n  \\n  \\n  \\nPage 90\\nMachine Learning Yearning-Draft\\nAndrew Ng'),\n",
       " Document(metadata={'creationdate': '', 'creator': 'PyPDF', 'page': 81, 'page_label': '82', 'producer': 'Skia/PDF m71', 'source': 'docs/NG2018.pdf', 'total_pages': 118}, page_content='Keep in mind that artificial data synthesis has its challenges: it is sometimes easier to create\\n \\nsynthetic data that appears realistic to a person than it is to create data that appears realistic\\n \\nto a computer. For example, suppose you have 1,000 hours of speech training data, but only\\n \\n1 hour of car noise. If you repeatedly use the same 1 hour of car noise with different portions\\n \\nfrom the original 1,000 hours of training data, you will end up with a synthetic dataset where\\n \\nthe same car noise is repeated over and over. While a person listening to this audio probably\\n \\nwould not be able to tell—all car noise sounds the same to most of us—it is possible that a\\n \\nlearning algorithm would “overfit” to the 1 hour of car noise. Thus, it could generalize poorly\\n \\nto a new audio clip where the car noise happens to sound different.\\n \\n \\nAlternatively, suppose you have 1,000 unique hours of car noise, but all of it was taken from\\n \\njust 10 different cars. In this case, it is possible for an algorithm to “overfit” to these 10 cars\\n \\nand perform poorly if tested on audio from a different car. Unfortunately, these problems\\n \\ncan be hard to spot.\\n \\n \\n \\n \\n \\nPage 82\\nMachine Learning Yearning-Draft\\nAndrew Ng')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_docs(docs):\n",
    "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap our vectorstore\n",
    "llm = OpenAI(temperature=0, model=\"gpt-3.5-turbo-instruct\")\n",
    "compressor = LLMChainExtractor.from_llm(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "\n",
      "• There is now a huge quantity of data available to train neural networks, and\n",
      "ANNs frequen tly outperform other ML techniques on ver\n",
      "y large and complex\n",
      "problems.\n",
      "• The tremendous increase in computing power since the 1990s now makes it pos‐\n",
      "sible to train large neural networks in a reasonable amount of time. This is in\n",
      "part due to Moore\n",
      "’s Law, but also thanks to the gaming industry, which has pro‐\n",
      "duced powerful GPU cards by the millions.\n",
      "• The training algorithms have been improved. To be fair they are only slightly dif‐\n",
      "ferent from the ones used in the 1990s, but these relatively small tweaks ha\n",
      "ve a\n",
      "huge positive impact.\n",
      "• Some theoretical limitations of ANNs have turned out to be benign in practice.\n",
      "For example, man\n",
      "y people thought that ANN training algorithms were doomed\n",
      "because they were likely to get stuck in local optima, but it turns out that this is\n",
      "rather rare in practice (or when it is the case, they are usually fairly close to the\n",
      "global optimum).\n",
      "• ANNs seem to have entered a virtuous circle of funding and progress. Amazing\n",
      "products based on ANNs regularly make the headline news, which pulls more\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 2:\n",
      "\n",
      "- \"Birds inspired us to fly, burdock plants inspired velcro, and nature has inspired many other inventions.\"\n",
      "- \"It seems only logical, then, to look at the brain’s architecture for inspiration on how to build an intelligent machine.\"\n",
      "- \"This is the key idea that inspired artificial neural networks (ANNs).\"\n",
      "- \"ANNs are at the very core of Deep Learning.\"\n",
      "- \"They are versatile, powerful, and scalable, making them ideal to tackle large and highly complex Machine Learning tasks.\"\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 3:\n",
      "\n",
      "products based on ANNs regularly make the headline news\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Document 4:\n",
      "\n",
      "1 Available on Hinton’s home page at http://ww w.cs.toronto.edu/~hinton/.\n",
      "2 Despite the fact that Y ann Lecun’s deep convolutional neural networks had worked well for image recognition\n",
      "since the 1990s, although they were not as general purpose.\n",
      "Preface\n",
      "The Machine Learning Tsunami\n",
      "In 2006, Geoffrey Hinton et al. published a paper1 showing how to train a deep neural\n",
      "network ca\n",
      "pable of recognizing handwritten digits with state-of-the-art precision\n",
      "(>98%). They branded this technique “Deep Learning. ” Training a deep neural net\n",
      "was widely considered impossible at the time, 2 and most researchers had abandoned\n",
      "the idea since the 1990s. This paper revived the interest of the scientific community\n",
      "and before long many new papers demonstrated that Deep Learning was not only\n",
      "possible, but capable of mind-blowing achievements that no other Machine Learning\n",
      "(ML) technique could hope to match (with the help of tremendous computing power\n",
      "and great amounts of data). This enthusiasm soon extended to many other areas of\n",
      "Machine Learning.\n"
     ]
    }
   ],
   "source": [
    "question = \"what did they say about ai?\"\n",
    "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
    "pretty_print_docs(compressed_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other types of Retrival\n",
    "\n",
    "It's worth noting that vectordb as not the only kind of tool to retrieve documents. \n",
    "\n",
    "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import SVMRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PDF\n",
    "loader = PyPDFLoader(\"docs/NG2023.pdf\")\n",
    "pages = loader.load()\n",
    "all_page_text=[p.page_content for p in pages]\n",
    "joined_page_text=\" \".join(all_page_text)\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
    "splits = text_splitter.split_text(joined_page_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
    "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='✓\\n✓\\nOvercoming Imposter Syndrome PAGE 40\\nMake Every Day Count\\nFinal Thoughts\\nEvery year on my birthday, I get to thinking about the days behind and those \\nthat may lie ahead.\\nWhen I ask friends, many choose a number in the hundreds of \\nthousands. (Many others can’t resist calculating the answer, \\nto my annoyance!)\\nWhen I was a grad student, I remember plugging my statistics \\ninto a mortality calculator to figure out my life expectancy. \\nThe calculator said I could expect to live a total of 27,649 \\ndays. It struck me how small this number is. I printed it in a \\nlarge font and pasted it on my office wall as a daily reminder.\\nThat’s all the days we have to spend with loved ones, learn, \\nbuild for the future, and help others. Whatever you’re doing \\ntoday, is it worth 1/30,000 of your life?\\nHow many days is a \\ntypical human lifespan?\\nMaybe you’re good at math; I’m sure you’ll be able to answer the following question \\nvia a quick calculation. But let me ask you a question, and please answer from \\nyour gut, without calculating.\\n20,000 days 100,000 days\\n1 million days 5 million days PAGE 41')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this book?\"\n",
    "docs_svm=svm_retriever.get_relevant_documents(question)\n",
    "docs_svm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={}, page_content='algorithms, deployment processes, and software stacks a particular company uses. You \\nmay be surprised — if you’re not already familiar with the data-centric AI movement — to \\nlearn how much time most machine learning engineers spend iteratively cleaning datasets.\\n✓\\n✓\\nWhat do you do in a typical week or day?\\nWhat are the most important tasks in this role?\\nWhat skills are most important for success?\\nHow does your team work together to accomplish its goals?\\nWhat is the hiring process?\\nConsidering candidates who stood out in the past, what enabled them to shine?\\n✓\\n✓\\n✓\\n✓\\n✓\\n✓\\nUsing Informational Interviews to Find the Right Job CHAPTER 8 PAGE 30\\nFinding someone to interview isn’t always easy, but many people who are in senior positions today \\nreceived help when they were new from those who had entered the field ahead of them, and many \\nare eager to pay it forward. If you can reach out to someone who’s already in your network — \\nperhaps a friend who made the transition ahead of you or someone who attended the same school \\nas you — that’s great! Meetups such as Pie & AI can also help you build your network.\\nFinally, be polite and professional, and thank the people you’ve interviewed. And when you get \\na chance, please pay it forward as well and help someone coming up after you. If you receive \\na request for an informational interview from someone in the DeepLearning.AI community, \\nI hope you’ll lean in to help them take a step up! If you’re interested in learning more about')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what did they say about ethics\"\n",
    "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
    "docs_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "current_date = datetime.datetime.now().date()\n",
    "if current_date < datetime.date(2023, 9, 2):\n",
    "    llm_name = \"gpt-3.5-turbo-0301\"\n",
    "else:\n",
    "    llm_name = \"gpt-3.5-turbo\"\n",
    "print(llm_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_68203/3010969844.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "persist_directory = 'docs/chroma/'\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this book?\"\n",
    "docs = vectordb.similarity_search(question,k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=llm_name, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RetrievalQA chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_17578/4094420968.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": question})\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' They said that there is now a huge quantity of data available to train neural networks, and ANNs frequently outperform other ML techniques on very large and complex problems.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer.\n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run chain\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Why to use neural networks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are best suited for end-to-end learning systems where the algorithm connects input directly to the desired output. They are successful in problems with abundant data but may not always be the best choice. Thanks for asking!'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'author': 'Aurélien Géron', 'creationdate': '2017-03-10T21:55:34+00:00', 'creator': 'AH CSS Formatter V6.2 MR4 for Linux64 : 6.2.6.18551 (2014/09/24 15:00JST)', 'moddate': '2017-05-16T09:54:54+08:00', 'page': 17, 'page_label': 'xvi', 'producer': 'Antenna House PDF Output Library 6.2.609 (Linux64)', 'source': 'docs/Geron2017.pdf', 'title': 'Hands-On Machine Learning with Scikit-Learn and TensorFlow', 'total_pages': 564, 'trapped': '/False'}, page_content='Part II, Neural Networks and Deep Learning, covers the following topics:\\n• Wha t are neural nets? Wha\\nt are they good for?\\n• Building and training neural nets using TensorFlow.\\n• The most important neural net architectures: feedforward neural nets, convolu‐\\ntional nets, recurrent nets, long short-term memory (LSTM) nets, and a\\nutoen‐\\ncoders.\\n• Techniques for training deep neural nets.\\n• Scaling neural networks for huge datasets.\\n• Reinforcement learning.\\nThe first part is based mostly on Scikit-Learn while the second part uses TensorFlow.\\nDon\\n’t jump into deep waters too hastily: while Deep Learning is no\\ndoubt one of the most exciting areas in Machine Learning, you\\nshould master the fundamentals first. Moreover, most problems\\ncan be solved quite well using simpler techniques such as Random\\nForests and Ensemble methods (discussed in Part I). Deep Learn‐\\ning is best suited for complex problems such as image recognition,\\nspeech recognition, or natural language processing, provided you\\nhave enough data, computing power, and patience.\\nOther Resources\\nMany resources are available to learn about Machine Learning. Andrew Ng’s ML\\ncourse on Coursera and Geoffrey Hinton’s course on neural networks and Deep\\nLearning are amazing, although they both require a significant time investment\\n(think months).\\nThere are also many interesting websites about Machine Learning, including of\\ncourse Scikit-Learn’s exceptional User Guide. Y ou may also enjoy Dataquest, which')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RetrievalQA limitations\n",
    " \n",
    "QA fails to preserve conversational history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are used because they can model complex functions efficiently, especially deep neural networks. They have a hierarchical architecture that allows them to automatically take advantage of the structured nature of real-world data. This hierarchical structure helps neural networks converge faster to good solutions and improves their ability to generalize to new datasets. Additionally, neural networks are commonly used in end-to-end learning systems, where the learning algorithm directly connects the input to the desired output, making them successful in problems with abundant data.'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Why to use Neural Networks?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The complex functions referred to in the context are those where multiple features are combined together to create more intricate features. These complex features aim to capture essential information from raw data more effectively. The idea is that by creating more sophisticated input features, the model can be simpler, easier to train, evaluate, and make better predictions.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what kind of complex functions do you mean?\"\n",
    "result = qa_chain({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chat - Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_68203/1956280058.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConversationalRetrievalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "retriever=vectordb.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever=retriever,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Why to use Neural Networks?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks are used because they can model complex functions efficiently, especially deep neural networks. They have a hierarchical architecture that allows them to automatically take advantage of the structured nature of real-world data. This hierarchical structure helps neural networks converge faster to a good solution and improves their ability to generalize to new datasets. Additionally, neural networks are commonly used in end-to-end learning systems, where the learning algorithm directly connects the input to the desired output, making them successful in problems with abundant data.'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"give examples to complex functions?\"\n",
    "result = qa({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Neural networks can efficiently model complex functions such as image captioning, machine translation, question answering, speech recognition, and text-to-speech synthesis. These tasks involve processing rich inputs like images, text, audio, and generating corresponding outputs, showcasing the capability of neural networks to handle diverse and complex functions.'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
