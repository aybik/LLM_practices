{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  \n",
    "import numpy as np\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.docstore.document import Document\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepseek Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ DeepSeek Model Versions & Recommendations\n",
    "\n",
    "DeepSeek offers various model sizes optimized for different use cases. Below is a comparison of the available versions to help you choose the best one for your needs.\n",
    "\n",
    "## âœ… Recommended Lightweight DeepSeek Versions\n",
    "\n",
    "| **Model**                 | **Command**                          | **Size**  | **Best For** |\n",
    "|---------------------------|------------------------------------|-----------|-------------|\n",
    "| **DeepSeek 1.5B (default)** | `ollama pull deepseek-r1:1.5b` | **1.5B params (~2GB RAM needed)** | Lightest version, fastest |\n",
    "| **DeepSeek 7B**            | `ollama pull deepseek-r1:7b` | **7B params (~10GB RAM needed)** | Balanced speed & power |\n",
    "| **DeepSeek 8B (Llama)**    | `ollama pull deepseek-r1:8b` | **8B params (~12GB RAM needed)** | Llama3-based, better reasoning |\n",
    "| **DeepSeek 14B**           | `ollama pull deepseek-r1:14b` | **14B params (~20GB RAM needed)** | More accurate but heavier |\n",
    "\n",
    "## My Choice: \n",
    "âœ… `deepseek-r1:1.5b`    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full RAG Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Overview**\n",
    "This pipeline allows me to:\n",
    "- **Extract text from PDFs**\n",
    "- **Chunk text into smaller sections**\n",
    "- **Embed text using embeddings**\n",
    "- **Store and retrieve embeddings using FAISS**\n",
    "- **Query the system using DeepSeek LLM via Ollama**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extracts text from a given PDF file.\"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "    return text if text.strip() else None  # Avoid empty documents\n",
    "\n",
    "def load_and_process_pdfs(pdf_files):\n",
    "    \"\"\"Loads multiple PDFs and extracts valid text.\"\"\"\n",
    "    documents = [extract_text_from_pdf(pdf) for pdf in pdf_files if extract_text_from_pdf(pdf)]\n",
    "    return [doc for doc in documents if isinstance(doc, str) and doc.strip()]  \n",
    "\n",
    "def split_text_into_chunks(documents, chunk_size=500, chunk_overlap=50):\n",
    "    \"\"\"Splits text into smaller chunks for efficient processing.\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = []\n",
    "    for doc in documents:\n",
    "        texts.extend(text_splitter.split_text(doc))\n",
    "    return texts\n",
    "\n",
    "def create_faiss_vectorstore(texts, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "    \"\"\"Generates embeddings and stores them in a FAISS vector database.\"\"\"\n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "    documents = [Document(page_content=text) for text in texts]  \n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "    print(\"âœ… FAISS vector store successfully created!\")\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline(pdf_files, query):\n",
    "    llm = Ollama(model=\"deepseek-r1:1.5b\") \n",
    "    documents = load_and_process_pdfs(pdf_files) \n",
    "    texts = split_text_into_chunks(documents)  \n",
    "    vectorstore = create_faiss_vectorstore(texts)  \n",
    "    \n",
    "    retriever = vectorstore.as_retriever()\n",
    "    qa_chain = RetrievalQA.from_chain_type(llm, retriever=retriever)\n",
    "    response = qa_chain.run(query)\n",
    "    clean_response = response.replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip()\n",
    "    return \"\\n\".join(clean_response.split(\". \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS vector store successfully created!\n",
      "Okay, so I'm trying to answer this question about machine learning\n",
      "The user has given me several books and some context from them\n",
      "Let me break it down step by step.\n",
      "\n",
      "First, they mentioned Stuart Russell and Peter Norvig's \"Artificial Intelligence: A Modern Approach\" which is a big book covering ML topics\n",
      "It includes things like algorithms and how they work, the bias-variance tradeoff, etc\n",
      "Then there's a chapter on ethics in computing from Berler and Brunnstein, 2001\n",
      "They talk about jobs being automated, leisure issues, uniqueness loss, AI uses, and accountability.\n",
      "\n",
      "They also pointed out that while ML is great for automation, it can cause serious ethical problems\n",
      "So the question is asking to summarize the key technical aspects and social aspects discussed in these books, specifically focusing on advancements in ML algorithms, ethical concerns, bias in AI, and societal impact of automation.\n",
      "\n",
      "Alright, so I need to cover each of these areas from both the technical and social points\n",
      "Let's start with the technical side.\n",
      "\n",
      "Technical Aspects:\n",
      "1\n",
      "**Algorithms**: They probably talk about different types like supervised, unsupervised, reinforcement learning\n",
      "Maybe mention neural networks since that's a big part now.\n",
      "2\n",
      "**Bias and Variance**: Discuss how ML models can have bias (underfitting) or variance (overfitting), the bias-variance tradeoff is key.\n",
      "3\n",
      "**Ethical Issues in ML**: They'd talk about fairness, accuracy vs\n",
      "justice, the role of data, algorithmic fairness, transparency, etc.\n",
      "\n",
      "Social Aspects:\n",
      "1\n",
      "**Automation Impact**: The book might discuss how automation affects jobs, leisure, uniqueness\n",
      "Like robots making decisions that humans can't see or interact with.\n",
      "2\n",
      "**Ethical Concerns**: There's a section on avoiding unintended consequencesâ€”like if an AI system is biased against someone, it could cause problems.\n",
      "3\n",
      "**Societal Impact**: The books likely talk about the broader effects of ML, like in healthcare, criminal justice, etc., but also the negative side.\n",
      "\n",
      "I should make sure to mention each point from both authors' sections and see how they tie together.\n",
      "\n",
      "Wait, I remember from the ethics book that it's not just about jobs being automated\n",
      "It could lead to automation affecting people's lives more than intended, like in housing, finance, etc\n",
      "So that's an important social aspect where ethical considerations matter beyond just economic outcomes.\n",
      "\n",
      "So putting this all together, I'll structure the answer by first listing each technical and social area, then provide specific points from the books.\n",
      "\n",
      "\n",
      "**Answer:**\n",
      "\n",
      "The provided books explore machine learning through both technical advancements and social implications:\n",
      "\n",
      "**Technical Aspects:**\n",
      "1\n",
      "**Algorithms**: The books discuss various ML algorithms, including supervised, unsupervised, and reinforcement learning\n",
      "Notably, neural networks are a major focus.\n",
      "2\n",
      "**Bias and Variance**: They delve into the bias-variance tradeoff, explaining how models can either underfit (high bias) or overfit (high variance), crucial for understanding model performance.\n",
      "3\n",
      "**Ethical Issues in ML**: The ethical concerns include fairness, accuracy vs\n",
      "justice, algorithmic fairness, transparency, and accountability.\n",
      "\n",
      "**Social Aspects:**\n",
      "1\n",
      "**Automation Impact**: Automation affects jobs, leisure, and uniqueness\n",
      "For instance, robots may make decisions humans can't see or interact with.\n",
      "2\n",
      "**Ethical Concerns**: Beyond job automation, ethical issues arise from unintended consequences, such as biased algorithms leading to systemic inequities.\n",
      "3\n",
      "**Societal Impact**: ML has significant effects on society, affecting healthcare, criminal justice, and environmental outcomes, though also introducing potential negative impacts.\n",
      "\n",
      "These books collectively provide insights into both the technical innovations of ML and their societal and ethical implications.\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\"Geron2017.pdf\", \"knafling2015.pdf\", \"Mohri2018.pdf\", \"NG2018.pdf\", \"NG2023.pdf\", \"Russell2010.pdf\", \"Zheng2018.pdf\"]\n",
    "query = '''\n",
    "Summarize the key technical and social aspects discussed in the provided books \n",
    "on machine learning. Specifically, highlight advancements in ML algorithms, \n",
    "ethical concerns, bias in AI, and the societal impact of automation.\n",
    "'''\n",
    "\n",
    "response = run_pipeline(pdf_files, query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up conversational retrieval with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_conversational_chain(vectorstore, model_name=\"deepseek-r1:1.5b\"):\n",
    "    \"\"\"Creates a retrieval-based QA system with memory.\"\"\"\n",
    "    llm = Ollama(model=model_name)  \n",
    "    memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(llm, retriever=vectorstore.as_retriever(), memory=memory)\n",
    "    return qa_chain\n",
    "\n",
    "def ask_question(qa_chain, query):\n",
    "    \"\"\"Asks a question and stores the conversation history.\"\"\"\n",
    "    response = qa_chain.invoke({\"question\": query})\n",
    "    print(\"ğŸ” Answer:\", response.get(\"answer\", \"No answer found.\"))\n",
    "    return response.get(\"answer\", \"No answer found.\")\n",
    "\n",
    "def run_pipeline_with_memory(pdf_files, query):\n",
    "    documents = load_and_process_pdfs(pdf_files)  \n",
    "    texts = split_text_into_chunks(documents) \n",
    "    \n",
    "    embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    documents = [Document(page_content=text) for text in texts]  \n",
    "    vectorstore = FAISS.from_documents(documents, embedding_model)\n",
    "    \n",
    "    qa_chain = setup_conversational_chain(vectorstore)\n",
    "    \n",
    "    answer = ask_question(qa_chain, query)\n",
    "    answer = answer.replace(\"<think>\", \"\").replace(\"</think>\", \"\").strip()\n",
    "\n",
    "    return answer, qa_chain\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6j/6_13thh50qqgx2lhw_0qf67m0000gn/T/ipykernel_25020/364125185.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Answer: <think>\n",
      "Okay, so I need to summarize the key technical and social aspects of machine learning books based on the given context. Let's break down what's provided.\n",
      "\n",
      "First, there are a few paragraphs about specific authors and their books. Stuart Russell and Peter Norvig wrote \"Artificial Intelligence: A Modern Approach,\" which is a comprehensive textbook covering a lot of topics including ML. Another author is John Langford from Carnegie Mellon University who has also written \"Revisiting the Bias-Variance Tradeoff.\" There's also a chapter titled \"Machine Learning for Data Science\" in this book, focusing on practical aspects.\n",
      "\n",
      "Then, there's an example about using case studies to explain concepts without getting into specifics. The book is used by many industries and helps leaders understand ML principles through examples from various fields.\n",
      "\n",
      "So the user wants me to list these technical and social aspects. From the context, I can gather:\n",
      "\n",
      "1. Technical Content: The book covers various topics in AI, machine learning, data visualization, bias-variance tradeoff, neural networks, deep learning, natural language processing, automated reasoning, and ethical considerations.\n",
      "2. Practical Tips and Resources: They include case studies, real-world examples, code snippets, detailed explanations of algorithms, and exercises to test understanding.\n",
      "3. Leadership Tools and Tools for Managing Teams: The book provides guidance on defining technical direction and using metrics, along with tips on effective communication.\n",
      "\n",
      "I think that's the main summary based on the provided context.\n",
      "</think>\n",
      "\n",
      "**Summary of Key Technical and Social Aspects in ML Books**\n",
      "\n",
      "1. **Technical Content:**\n",
      "   - Comprehensive coverage of AI and machine learning topics, including data visualization, bias-variance tradeoff, neural networks, deep learning, natural language processing, automated reasoning, ethical considerations, optimization techniques, model evaluation, ensemble methods, feature engineering, reinforcement learning, generative models like GANs, transformers for sequence modeling, transfer learning, domain adaptation, domain generalization, active learning strategies.\n",
      "\n",
      "2. **Practical Tips and Resources:**\n",
      "   - Utilizes case studies across multiple industries to illustrate fundamental concepts without delving into specifics.\n",
      "   - Provides real-world examples and explanations of algorithms with detailed walkthroughs and step-by-step derivations.\n",
      "   - Includes exercises for hands-on practice, covering datasets, model design, implementation details, evaluation metrics, and ethical considerations.\n",
      "\n",
      "3. **Leadership Tools and Team Management:**\n",
      "   - Offers guidance on setting technical direction and defining project scopes.\n",
      "   - Provides leadership tips, such as using single-number metrics when appropriate but emphasizing the importance of diverse perspectives in communication to avoid biases.\n",
      "   - Includes tools and techniques for managing teams effectively within a data-driven context.\n"
     ]
    }
   ],
   "source": [
    "pdf_files = [\"Geron2017.pdf\", \"knafling2015.pdf\", \"Mohri2018.pdf\", \"NG2018.pdf\", \"NG2023.pdf\", \"Russell2010.pdf\", \"Zheng2018.pdf\"]\n",
    "query = \"Summarize key technical and social aspects in ML books.\"\n",
    "answer, qa_chain = run_pipeline_with_memory(pdf_files, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Answer: <think>\n",
      "å—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯MLæ•™æçš„ä¸»è¦æŠ€æœ¯å’Œç¤¾ä¼šå†…å®¹ã€‚æˆ‘éœ€è¦å…ˆç†æ¸…è¿™äº›æ–¹é¢ã€‚\n",
      "\n",
      "é¦–å…ˆï¼ŒæŠ€æœ¯æ–¹é¢åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€ç‰¹å¾å·¥ç¨‹ã€ç®—æ³•è®¾è®¡ã€æ¨¡å‹è¯„ä¼°ã€éƒ¨ç½²ä¸ä¼˜åŒ–ã€åº”ç”¨åœºæ™¯ç­‰ã€‚è¿™äº›éƒ½æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„æ ¸å¿ƒé—®é¢˜å’Œæ–¹æ³•è®ºã€‚\n",
      "\n",
      "ç„¶åæ˜¯ç¤¾äº¤æ–¹é¢ï¼Œæ¶‰åŠä¼¦ç†ã€å¯è§£é‡Šæ€§ã€ç¤¾åŒºå‚ä¸ã€å›¢é˜Ÿåä½œã€å…¬ä¼—è®¤çŸ¥å’Œåé¦ˆæœºåˆ¶ç­‰ã€‚è¿™éƒ¨åˆ†æ˜¯å…³äºå¦‚ä½•åœ¨æŠ€æœ¯ä¸Šå®æ–½MLï¼Œå¹¶è€ƒè™‘äººç±»çš„è§†è§’ã€‚\n",
      "\n",
      "æ€»ç»“ä¸€ä¸‹ï¼Œç”¨æˆ·å¯èƒ½å¸Œæœ›äº†è§£æ•™æä¸­ç³»ç»Ÿåœ°æ¶µç›–äº†æŠ€æœ¯åŸç†å’ŒæŠ€æœ¯åº”ç”¨ï¼ŒåŒæ—¶ä¹Ÿåœ¨ç¤¾ä¼šå±‚é¢è€ƒè™‘ç›¸å…³é—®é¢˜ã€‚è¿™æ ·å¯ä»¥å…¨é¢å±•ç¤ºæœºå™¨å­¦ä¹ çš„å‘å±•å’Œå½±å“ã€‚\n",
      "</think>\n",
      "\n",
      "åœ¨ ML æ•™æä¸­ï¼Œæœ‰å“ªäº›ä¸»è¦çš„æŠ€æœ¯å’Œç¤¾äº¤æ–¹é¢å†…å®¹ï¼Ÿ\n",
      "\n",
      "ä¸»è¦çš„æŠ€æœ¯æ–¹é¢åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€ç‰¹å¾å·¥ç¨‹ã€ç®—æ³•è®¾è®¡ã€æ¨¡å‹è¯„ä¼°ã€éƒ¨ç½²ä¸ä¼˜åŒ–ä»¥åŠåº”ç”¨åœºæ™¯ç­‰ã€‚\n",
      "\n",
      "ä¸»è¦çš„ç¤¾äº¤æ–¹é¢åŒ…æ‹¬ä¼¦ç†ã€å¯è§£é‡Šæ€§ã€ç¤¾åŒºå‚ä¸ã€å›¢é˜Ÿåä½œã€å…¬ä¼—è®¤çŸ¥å’Œåé¦ˆæœºåˆ¶ç­‰ã€‚\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nå—¯ï¼Œç”¨æˆ·é—®çš„æ˜¯MLæ•™æçš„ä¸»è¦æŠ€æœ¯å’Œç¤¾ä¼šå†…å®¹ã€‚æˆ‘éœ€è¦å…ˆç†æ¸…è¿™äº›æ–¹é¢ã€‚\\n\\né¦–å…ˆï¼ŒæŠ€æœ¯æ–¹é¢åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€ç‰¹å¾å·¥ç¨‹ã€ç®—æ³•è®¾è®¡ã€æ¨¡å‹è¯„ä¼°ã€éƒ¨ç½²ä¸ä¼˜åŒ–ã€åº”ç”¨åœºæ™¯ç­‰ã€‚è¿™äº›éƒ½æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„æ ¸å¿ƒé—®é¢˜å’Œæ–¹æ³•è®ºã€‚\\n\\nç„¶åæ˜¯ç¤¾äº¤æ–¹é¢ï¼Œæ¶‰åŠä¼¦ç†ã€å¯è§£é‡Šæ€§ã€ç¤¾åŒºå‚ä¸ã€å›¢é˜Ÿåä½œã€å…¬ä¼—è®¤çŸ¥å’Œåé¦ˆæœºåˆ¶ç­‰ã€‚è¿™éƒ¨åˆ†æ˜¯å…³äºå¦‚ä½•åœ¨æŠ€æœ¯ä¸Šå®æ–½MLï¼Œå¹¶è€ƒè™‘äººç±»çš„è§†è§’ã€‚\\n\\næ€»ç»“ä¸€ä¸‹ï¼Œç”¨æˆ·å¯èƒ½å¸Œæœ›äº†è§£æ•™æä¸­ç³»ç»Ÿåœ°æ¶µç›–äº†æŠ€æœ¯åŸç†å’ŒæŠ€æœ¯åº”ç”¨ï¼ŒåŒæ—¶ä¹Ÿåœ¨ç¤¾ä¼šå±‚é¢è€ƒè™‘ç›¸å…³é—®é¢˜ã€‚è¿™æ ·å¯ä»¥å…¨é¢å±•ç¤ºæœºå™¨å­¦ä¹ çš„å‘å±•å’Œå½±å“ã€‚\\n</think>\\n\\nåœ¨ ML æ•™æä¸­ï¼Œæœ‰å“ªäº›ä¸»è¦çš„æŠ€æœ¯å’Œç¤¾äº¤æ–¹é¢å†…å®¹ï¼Ÿ\\n\\nä¸»è¦çš„æŠ€æœ¯æ–¹é¢åŒ…æ‹¬æ•°æ®å‡†å¤‡ã€ç‰¹å¾å·¥ç¨‹ã€ç®—æ³•è®¾è®¡ã€æ¨¡å‹è¯„ä¼°ã€éƒ¨ç½²ä¸ä¼˜åŒ–ä»¥åŠåº”ç”¨åœºæ™¯ç­‰ã€‚\\n\\nä¸»è¦çš„ç¤¾äº¤æ–¹é¢åŒ…æ‹¬ä¼¦ç†ã€å¯è§£é‡Šæ€§ã€ç¤¾åŒºå‚ä¸ã€å›¢é˜Ÿåä½œã€å…¬ä¼—è®¤çŸ¥å’Œåé¦ˆæœºåˆ¶ç­‰ã€‚'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follow_up_query = \"Which of the books focus more on ethical aspects of AI\"\n",
    "ask_question(qa_chain, follow_up_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Answer: <think>\n",
      "å—¯ï¼Œç”¨æˆ·è®©æˆ‘æŠŠä¹‹å‰çš„è‹±æ–‡æé—®é‡è¿°æˆä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜ã€‚æˆ‘éœ€è¦ä»”ç»†åˆ†æä»–ä»¬çš„åŸæ–‡ï¼Œçœ‹çœ‹ä»–ä»¬åˆ°åº•æƒ³è¦ä»€ä¹ˆã€‚\n",
      "\n",
      "ä»–ä»¬æåˆ°äº†ä¸€æœ¬å…³äºæœºå™¨å­¦ä¹ çš„ä¹¦ç±ï¼Œè¯¢é—®å“ªäº›ä¹¦æ›´å¤šåœ°å…³æ³¨ä¼¦ç†æ–¹é¢çš„å†…å®¹ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°æœºå™¨å­¦ä¹ æŠ€æœ¯ä¸­çš„é“å¾·é—®é¢˜ã€ä¼¦ç†å†³ç­–æˆ–è€…æ³•å¾‹å±‚é¢çš„å½±å“ã€‚\n",
      "\n",
      "æ¥ä¸‹æ¥ï¼Œæˆ‘è¦ç¡®ä¿æ–°æé—®æ¸…æ™°æ˜ç¡®ï¼Œä¸å¼•å…¥å…¶ä»–ä¿¡æ¯æˆ–å‡è®¾ï¼Œåªä¸“æ³¨äºç”¨æˆ·çš„é—®é¢˜ã€‚æ‰€ä»¥ï¼Œæˆ‘å°†é‡æ–°è¡¨è¿°ä¸ºï¼šâ€œWhich of the ML textbooks focus more on ethical considerations and practices in AIâ€ï¼Ÿ\n",
      "\n",
      "æ˜¯çš„ï¼Œè¿™æ ·æ—¢ä¿æŒäº†åŸæ„ï¼Œåˆç‹¬ç«‹è§£ç­”äº†é—®é¢˜ï¼Œä¸ä¼šæœ‰ä»»ä½•æ··æ·†ã€‚\n",
      "</think>\n",
      "\n",
      "Which of the ML textbooks focus more on ethical considerations and practices in AI?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<think>\\nå—¯ï¼Œç”¨æˆ·è®©æˆ‘æŠŠä¹‹å‰çš„è‹±æ–‡æé—®é‡è¿°æˆä¸€ä¸ªç‹¬ç«‹çš„é—®é¢˜ã€‚æˆ‘éœ€è¦ä»”ç»†åˆ†æä»–ä»¬çš„åŸæ–‡ï¼Œçœ‹çœ‹ä»–ä»¬åˆ°åº•æƒ³è¦ä»€ä¹ˆã€‚\\n\\nä»–ä»¬æåˆ°äº†ä¸€æœ¬å…³äºæœºå™¨å­¦ä¹ çš„ä¹¦ç±ï¼Œè¯¢é—®å“ªäº›ä¹¦æ›´å¤šåœ°å…³æ³¨ä¼¦ç†æ–¹é¢çš„å†…å®¹ã€‚è¿™å¯èƒ½æ¶‰åŠåˆ°æœºå™¨å­¦ä¹ æŠ€æœ¯ä¸­çš„é“å¾·é—®é¢˜ã€ä¼¦ç†å†³ç­–æˆ–è€…æ³•å¾‹å±‚é¢çš„å½±å“ã€‚\\n\\næ¥ä¸‹æ¥ï¼Œæˆ‘è¦ç¡®ä¿æ–°æé—®æ¸…æ™°æ˜ç¡®ï¼Œä¸å¼•å…¥å…¶ä»–ä¿¡æ¯æˆ–å‡è®¾ï¼Œåªä¸“æ³¨äºç”¨æˆ·çš„é—®é¢˜ã€‚æ‰€ä»¥ï¼Œæˆ‘å°†é‡æ–°è¡¨è¿°ä¸ºï¼šâ€œWhich of the ML textbooks focus more on ethical considerations and practices in AIâ€ï¼Ÿ\\n\\næ˜¯çš„ï¼Œè¿™æ ·æ—¢ä¿æŒäº†åŸæ„ï¼Œåˆç‹¬ç«‹è§£ç­”äº†é—®é¢˜ï¼Œä¸ä¼šæœ‰ä»»ä½•æ··æ·†ã€‚\\n</think>\\n\\nWhich of the ML textbooks focus more on ethical considerations and practices in AI?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "follow_up_query = \"Can you please answer my previous question in English?\"\n",
    "ask_question(qa_chain, follow_up_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lewagon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
